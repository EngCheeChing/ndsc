{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcualte_acc(x, y):\n",
    "    count = 0\n",
    "    for i, j in enumerate(x):\n",
    "        if j == y[i]:\n",
    "            count += 1\n",
    "    print(count/len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# beauty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "beauty_paths = glob.glob('predictions/beauty/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['predictions/beauty\\\\conv1d_1',\n",
       " 'predictions/beauty\\\\conv1d_2layers',\n",
       " 'predictions/beauty\\\\conv1d_3',\n",
       " 'predictions/beauty\\\\gru',\n",
       " 'predictions/beauty\\\\lstm']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beauty_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_paths = glob.glob('predictions/test/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['predictions/test\\\\conv1d_1.npy',\n",
       " 'predictions/test\\\\conv1d_2layers.npy',\n",
       " 'predictions/test\\\\conv1d_3.npy',\n",
       " 'predictions/test\\\\gru.npy',\n",
       " 'predictions/test\\\\lstm.npy']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(172402, 17)\n"
     ]
    }
   ],
   "source": [
    "test_set = np.load(test_paths[0])[:, :17]\n",
    "print(test_set.shape)\n",
    "for i in test_paths[1:]:\n",
    "    test_set = np.append(test_set, np.load(i)[:, :17], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_set[:76545, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    "        \"objective\" : \"multiclass\",\n",
    "        \"num_class\" : num_classes,\n",
    "        \"num_leaves\" : 63,\n",
    "        \"max_depth\": -1,\n",
    "        \"learning_rate\" : 0.01,\n",
    "        \"bagging_fraction\" : 0.9,  # subsample\n",
    "        \"feature_fraction\" : 0.9,  # colsample_bytree\n",
    "        \"bagging_freq\" : 5,        # subsample_freq\n",
    "        \"bagging_seed\" : 2019,\n",
    "        'max_bin': 63,\n",
    "        #'device': 'gpu',\n",
    "        'metric': 'multi_logloss',\n",
    "        'multi_logloss': 'gbdt'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57317,)\n",
      "(57317,)\n",
      "(57317,)\n",
      "(57316,)\n",
      "(57316,)\n"
     ]
    }
   ],
   "source": [
    "for i in indexes:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions/beauty\\conv1d_1\\beauty_predictions_0.npy\n",
      "(57317, 17)\n",
      "predictions/beauty\\conv1d_1\\beauty_predictions_1.npy\n",
      "(57317, 17)\n",
      "predictions/beauty\\conv1d_1\\beauty_predictions_2.npy\n",
      "(57317, 17)\n",
      "predictions/beauty\\conv1d_1\\beauty_predictions_3.npy\n",
      "(57316, 17)\n",
      "predictions/beauty\\conv1d_1\\beauty_predictions_4.npy\n",
      "(57316, 17)\n",
      "predictions/beauty\\conv1d_2layers\\beauty_predictions_0.npy\n",
      "(57317, 17)\n",
      "predictions/beauty\\conv1d_2layers\\beauty_predictions_1.npy\n",
      "(57317, 17)\n",
      "predictions/beauty\\conv1d_2layers\\beauty_predictions_2.npy\n",
      "(57317, 17)\n",
      "predictions/beauty\\conv1d_2layers\\beauty_predictions_3.npy\n",
      "(57316, 17)\n",
      "predictions/beauty\\conv1d_2layers\\beauty_predictions_4.npy\n",
      "(57316, 17)\n",
      "predictions/beauty\\conv1d_3\\beauty_predictions_0.npy\n",
      "(57317, 17)\n",
      "predictions/beauty\\conv1d_3\\beauty_predictions_1.npy\n",
      "(57317, 17)\n",
      "predictions/beauty\\conv1d_3\\beauty_predictions_2.npy\n",
      "(57317, 17)\n",
      "predictions/beauty\\conv1d_3\\beauty_predictions_3.npy\n",
      "(57316, 17)\n",
      "predictions/beauty\\conv1d_3\\beauty_predictions_4.npy\n",
      "(57316, 17)\n",
      "predictions/beauty\\gru\\beauty_predictions_0.npy\n",
      "(57317, 17)\n",
      "predictions/beauty\\gru\\beauty_predictions_1.npy\n",
      "(57317, 17)\n",
      "predictions/beauty\\gru\\beauty_predictions_2.npy\n",
      "(57317, 17)\n",
      "predictions/beauty\\gru\\beauty_predictions_3.npy\n",
      "(57316, 17)\n",
      "predictions/beauty\\gru\\beauty_predictions_4.npy\n",
      "(57316, 17)\n",
      "predictions/beauty\\lstm\\beauty_predictions_0.npy\n",
      "(57317, 17)\n",
      "predictions/beauty\\lstm\\beauty_predictions_1.npy\n",
      "(57317, 17)\n",
      "predictions/beauty\\lstm\\beauty_predictions_2.npy\n",
      "(57317, 17)\n",
      "predictions/beauty\\lstm\\beauty_predictions_3.npy\n",
      "(57316, 17)\n",
      "predictions/beauty\\lstm\\beauty_predictions_4.npy\n",
      "(57316, 17)\n"
     ]
    }
   ],
   "source": [
    "for j in range(len(beauty_paths)):\n",
    "    for i in range(5):\n",
    "        print(glob.glob(beauty_paths[j]+'/*')[i])\n",
    "        print(np.load(glob.glob(beauty_paths[j]+'/*')[i]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold_0\n",
      "0\n",
      "(229266, 85)\n",
      "(57317, 85)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.17311\tvalid_1's multi_logloss: 1.20785\n",
      "[200]\ttraining's multi_logloss: 0.810856\tvalid_1's multi_logloss: 0.869933\n",
      "[300]\ttraining's multi_logloss: 0.668413\tvalid_1's multi_logloss: 0.752157\n",
      "[400]\ttraining's multi_logloss: 0.597806\tvalid_1's multi_logloss: 0.707006\n",
      "[500]\ttraining's multi_logloss: 0.554111\tvalid_1's multi_logloss: 0.687881\n",
      "[600]\ttraining's multi_logloss: 0.522534\tvalid_1's multi_logloss: 0.678782\n",
      "[700]\ttraining's multi_logloss: 0.497822\tvalid_1's multi_logloss: 0.674467\n",
      "[800]\ttraining's multi_logloss: 0.477977\tvalid_1's multi_logloss: 0.672457\n",
      "[900]\ttraining's multi_logloss: 0.461566\tvalid_1's multi_logloss: 0.67178\n",
      "[1000]\ttraining's multi_logloss: 0.447506\tvalid_1's multi_logloss: 0.671876\n",
      "Early stopping, best iteration is:\n",
      "[923]\ttraining's multi_logloss: 0.458147\tvalid_1's multi_logloss: 0.671741\n",
      "fold_1\n",
      "1\n",
      "(229266, 85)\n",
      "(57317, 85)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.17461\tvalid_1's multi_logloss: 1.20444\n",
      "[200]\ttraining's multi_logloss: 0.812713\tvalid_1's multi_logloss: 0.865172\n",
      "[300]\ttraining's multi_logloss: 0.670681\tvalid_1's multi_logloss: 0.746163\n",
      "[400]\ttraining's multi_logloss: 0.600364\tvalid_1's multi_logloss: 0.699841\n",
      "[500]\ttraining's multi_logloss: 0.556799\tvalid_1's multi_logloss: 0.679906\n",
      "[600]\ttraining's multi_logloss: 0.525256\tvalid_1's multi_logloss: 0.670262\n",
      "[700]\ttraining's multi_logloss: 0.500404\tvalid_1's multi_logloss: 0.66532\n",
      "[800]\ttraining's multi_logloss: 0.480058\tvalid_1's multi_logloss: 0.662999\n",
      "[900]\ttraining's multi_logloss: 0.463552\tvalid_1's multi_logloss: 0.662027\n",
      "[1000]\ttraining's multi_logloss: 0.449563\tvalid_1's multi_logloss: 0.661952\n",
      "Early stopping, best iteration is:\n",
      "[965]\ttraining's multi_logloss: 0.454265\tvalid_1's multi_logloss: 0.661869\n",
      "fold_2\n",
      "2\n",
      "(229266, 85)\n",
      "(57317, 85)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.17318\tvalid_1's multi_logloss: 1.20991\n",
      "[200]\ttraining's multi_logloss: 0.811027\tvalid_1's multi_logloss: 0.871971\n",
      "[300]\ttraining's multi_logloss: 0.668666\tvalid_1's multi_logloss: 0.753341\n",
      "[400]\ttraining's multi_logloss: 0.598164\tvalid_1's multi_logloss: 0.706971\n",
      "[500]\ttraining's multi_logloss: 0.55476\tvalid_1's multi_logloss: 0.686603\n",
      "[600]\ttraining's multi_logloss: 0.522994\tvalid_1's multi_logloss: 0.676718\n",
      "[700]\ttraining's multi_logloss: 0.498196\tvalid_1's multi_logloss: 0.671519\n",
      "[800]\ttraining's multi_logloss: 0.478189\tvalid_1's multi_logloss: 0.668809\n",
      "[900]\ttraining's multi_logloss: 0.461853\tvalid_1's multi_logloss: 0.667585\n",
      "[1000]\ttraining's multi_logloss: 0.447966\tvalid_1's multi_logloss: 0.667281\n",
      "[1100]\ttraining's multi_logloss: 0.435619\tvalid_1's multi_logloss: 0.667362\n",
      "Early stopping, best iteration is:\n",
      "[1045]\ttraining's multi_logloss: 0.442326\tvalid_1's multi_logloss: 0.667252\n",
      "fold_3\n",
      "3\n",
      "(229267, 85)\n",
      "(57316, 85)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.17264\tvalid_1's multi_logloss: 1.21453\n",
      "[200]\ttraining's multi_logloss: 0.810519\tvalid_1's multi_logloss: 0.876537\n",
      "[300]\ttraining's multi_logloss: 0.668221\tvalid_1's multi_logloss: 0.757311\n",
      "[400]\ttraining's multi_logloss: 0.597731\tvalid_1's multi_logloss: 0.710003\n",
      "[500]\ttraining's multi_logloss: 0.553955\tvalid_1's multi_logloss: 0.689051\n",
      "[600]\ttraining's multi_logloss: 0.522396\tvalid_1's multi_logloss: 0.678749\n",
      "[700]\ttraining's multi_logloss: 0.497708\tvalid_1's multi_logloss: 0.67339\n",
      "[800]\ttraining's multi_logloss: 0.477454\tvalid_1's multi_logloss: 0.670646\n",
      "[900]\ttraining's multi_logloss: 0.461039\tvalid_1's multi_logloss: 0.669351\n",
      "[1000]\ttraining's multi_logloss: 0.447149\tvalid_1's multi_logloss: 0.668939\n",
      "[1100]\ttraining's multi_logloss: 0.434798\tvalid_1's multi_logloss: 0.669065\n",
      "Early stopping, best iteration is:\n",
      "[1020]\ttraining's multi_logloss: 0.444582\tvalid_1's multi_logloss: 0.668926\n",
      "fold_4\n",
      "4\n",
      "(229267, 85)\n",
      "(57316, 85)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.173\tvalid_1's multi_logloss: 1.21693\n",
      "[200]\ttraining's multi_logloss: 0.810611\tvalid_1's multi_logloss: 0.877946\n",
      "[300]\ttraining's multi_logloss: 0.668072\tvalid_1's multi_logloss: 0.758184\n",
      "[400]\ttraining's multi_logloss: 0.597343\tvalid_1's multi_logloss: 0.711046\n",
      "[500]\ttraining's multi_logloss: 0.553541\tvalid_1's multi_logloss: 0.690455\n",
      "[600]\ttraining's multi_logloss: 0.521987\tvalid_1's multi_logloss: 0.680496\n",
      "[700]\ttraining's multi_logloss: 0.497023\tvalid_1's multi_logloss: 0.675415\n",
      "[800]\ttraining's multi_logloss: 0.477001\tvalid_1's multi_logloss: 0.672859\n",
      "[900]\ttraining's multi_logloss: 0.460454\tvalid_1's multi_logloss: 0.67163\n",
      "[1000]\ttraining's multi_logloss: 0.446499\tvalid_1's multi_logloss: 0.671151\n",
      "[1100]\ttraining's multi_logloss: 0.434096\tvalid_1's multi_logloss: 0.671266\n",
      "Early stopping, best iteration is:\n",
      "[1000]\ttraining's multi_logloss: 0.446499\tvalid_1's multi_logloss: 0.671151\n"
     ]
    }
   ],
   "source": [
    "test_output = np.zeros((test_set.shape[0], 17))\n",
    "for i in range(5):\n",
    "    print('fold_{}'.format(i))\n",
    "    lst = [0,1,2,3,4]\n",
    "    lst.remove(i)\n",
    "\n",
    "    trn_set = np.load(glob.glob(beauty_paths[0]+'/*')[lst[0]])\n",
    "    val_set = np.load(glob.glob(beauty_paths[0]+'/*')[i])\n",
    "    \n",
    "    for j in beauty_paths[1:]:\n",
    "        trn_set = np.append(trn_set, np.load(glob.glob(j+'/*')[lst[0]]), axis=1)\n",
    "        val_set = np.append(val_set, np.load(glob.glob(j+'/*')[i]), axis=1)\n",
    "    #trn_set = trn_set.reshape(trn_set.shape[0], 1)\n",
    "        \n",
    "    for x in lst[1:]:\n",
    "        one_row = np.load(glob.glob(beauty_paths[0]+'/*')[x])\n",
    "        for j in beauty_paths[1:]:\n",
    "            one_row = np.append(one_row, np.load(glob.glob(j+'/*')[x]), axis=1)\n",
    "        trn_set = np.append(trn_set, one_row, axis=0)\n",
    "    \n",
    "    indexes = np.load('np_array/trn_index_b_fold.npy')\n",
    "    index = int(glob.glob(beauty_paths[0] + '/*')[i][-5])\n",
    "    print(index)\n",
    "    val_index = indexes[index]\n",
    "    other_lst = [0,1,2,3,4]\n",
    "    other_lst.remove(index)\n",
    "    trn_index = indexes[other_lst[0]]\n",
    "    other_lst.remove(other_lst[0])\n",
    "    for num in other_lst:\n",
    "        trn_index = np.append(trn_index, indexes[num])\n",
    "        \n",
    "    labels_trn = train.iloc[trn_index, 2]\n",
    "    labels_trn = np.array(labels_trn)\n",
    "\n",
    "    labels_val = train.iloc[val_index, 2]\n",
    "    labels_val = np.array(labels_val)\n",
    "    \n",
    "    print(trn_set.shape)\n",
    "    print(val_set.shape)\n",
    "    lgtrain, lgval = lgb.Dataset(trn_set, labels_trn), lgb.Dataset(val_set, labels_val)\n",
    "    lgbmodel = lgb.train(params, lgtrain, 2000, valid_sets=[lgtrain, lgval], early_stopping_rounds=100, verbose_eval=100)\n",
    "    pred = lgbmodel.predict(val_set)\n",
    "    np.save('first_layer/five_nlp_{}'.format(index), pred)\n",
    "    pred = lgbmodel.predict(test_set)\n",
    "    test_output += pred/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('first_layer/beauty_five_test.npy', test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7924350541724096\n"
     ]
    }
   ],
   "source": [
    "calcualte_acc(predictions, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76545, 17)\n",
      "(55440, 14)\n",
      "(40417, 27)\n"
     ]
    }
   ],
   "source": [
    "b = np.load('first_layer/beauty_five_test.npy')\n",
    "print(b.shape)\n",
    "f = np.load('first_layer/fashion_five_test.npy')\n",
    "print(f.shape)\n",
    "m = np.load('first_layer/mobile_five_test.npy')\n",
    "print(m.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=np.zeros((76545+55440+40417, 58))\n",
    "output[:76545, :17] = b\n",
    "output[76545:55440+76545, 17:31] = f\n",
    "output[55440+76545:, 31:] = m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i in output:\n",
    "    predictions.append(list(i).index(i.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('nlp_test.npy', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172402"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "submission = test[['itemid']]\n",
    "submission['Category'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
