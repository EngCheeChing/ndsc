{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "d139846d0cb75fe7d21d11d664b0c3d89091ce48"
   },
   "outputs": [],
   "source": [
    "# references https://www.kaggle.com/mihaskalic/lstm-is-all-you-need-well-maybe-embeddings-also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "38244aed5db8a0c7be292ff1b20ea13aeb8f3531"
   },
   "outputs": [],
   "source": [
    "from pymagnitude import Magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "f9d27911bfb214a737d44127bfc091ee460c6dc1"
   },
   "outputs": [],
   "source": [
    "vectors = Magnitude(\"../input/magnitudes/wiki-news-300d-1M.magnitude\", \n",
    "                    ngram_oov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy as np\n",
    "train_df = pd.read_csv(\"../input/ndsc-beginner/train.csv\")\n",
    "submit_df = pd.read_csv(\"../input/ndsc-beginner/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "empyt_emb = np.zeros(300)  \n",
    "\n",
    "def text_to_array(text):\n",
    "    embeds = vectors.query(text.split())[:99]\n",
    "    return np.append(embeds,[empyt_emb] * max(0,100 - len(embeds)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:05<00:00, 170.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.867862224578857\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm # progress bar\n",
    "start_time = time.time()\n",
    "train_embeds = []\n",
    "for X_text in tqdm(train_df[\"title\"][:]):\n",
    "    train_embeds.append([text_to_array(X_text)])\n",
    "print(time.time()-start_time)\n",
    "\n",
    "np.save(\"train_df-pymag-wiki-feb27.npy\", np.array(train_embeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:04<00:00, 207.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.8181328773498535\n"
     ]
    }
   ],
   "source": [
    "import time  # tdqm don't work well here\n",
    "start_time = time.time()\n",
    "submit_embeds = []\n",
    "for X_text in tqdm(submit_df[\"title\"][:]):\n",
    "    submit_embeds.append([text_to_array(X_text)])\n",
    "print(time.time()-start_time)\n",
    "\n",
    "np.save(\"submit_df-pymag-wiki-feb27.npy\", np.array(submit_embeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook keras-pymag-wiki-loader.ipynb to python\n",
      "[NbConvertApp] Writing 1319 bytes to keras-pymag-wiki-loader.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert keras-pymag-wiki-loader.ipynb --to python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
