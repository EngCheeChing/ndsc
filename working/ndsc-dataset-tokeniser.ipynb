{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6f5ea96dfcc682c232d6cbb6cebd8b48ecabf8fe"
   },
   "source": [
    "### Preface\n",
    "\n",
    "Hello . This is basically cutting and pasting from the amazing kernels of this competition. Please notify me if I don't attribute something correctly.\n",
    "\n",
    "* https://www.kaggle.com/gmhost/gru-capsule\n",
    "* How to: Preprocessing when using embeddings\n",
    "https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings\n",
    "* Improve your Score with some Text Preprocessing https://www.kaggle.com/theoviel/improve-your-score-with-some-text-preprocessing\n",
    "* Simple attention layer taken from https://github.com/mttk/rnn-classifier/blob/master/model.py\n",
    "* https://www.kaggle.com/ziliwang/baseline-pytorch-bilstm\n",
    "* https://www.kaggle.com/hengzheng/pytorch-starter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "710ed17d0c57bd287be0ee3b2782a53a54510561"
   },
   "source": [
    "## IMPORTS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "abb7e3c30b8a412a50c6b451c49939e3cf4bc11b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time_ = time.time()\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import re\n",
    "# import torch\n",
    "# from torchtext import data\n",
    "# import spacy\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas(desc='Progress')\n",
    "from collections import Counter\n",
    "# from textblob import TextBlob\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torch.nn.functional as F\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "# from torch.autograd import Variable\n",
    "# from torchtext.data import Example\n",
    "from sklearn.metrics import f1_score\n",
    "# import torchtext\n",
    "import os \n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# cross validation and metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "# from torch.optim.optimizer import Optimizer\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9a4ff5590a6f152dc1bec5aeca79aef10218f7de"
   },
   "source": [
    "### Basic Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "deee49df5ca1c4413f71677939e26aa1ff784e44",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embed_size = 300 # how big is each word vector\n",
    "max_features = 120000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 100 # max number of words in a question to use\n",
    "batch_size = 512 # how many samples to process at once\n",
    "n_epochs = 5 # how many times to iterate over all samples\n",
    "n_splits = 5 # Number of K-fold Splits\n",
    "\n",
    "SEED = 1029"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "654cbe3c8a1f2a618a2441afe00df3b4a89e0a58"
   },
   "source": [
    "### Ensure determinism in the results\n",
    "\n",
    "A common headache in this competition is the lack of determinism in the results due to cudnn. The following Kernel has a solution in Pytorch.\n",
    "\n",
    "See https://www.kaggle.com/hengzheng/pytorch-starter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "58bbf87335799247586aaed16531f4d28d10ed4a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=1029):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "#     torch.manual_seed(seed)\n",
    "#     torch.cuda.manual_seed(seed)\n",
    "#     torch.backends.cudnn.deterministic = True\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c890692644acce2dc4f6e2f929d6d294faca4ad2"
   },
   "source": [
    "### Code for Loading Embeddings\n",
    "\n",
    "Functions taken from the kernel:https://www.kaggle.com/gmhost/gru-capsule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymagnitude import Magnitude\n",
    "\n",
    "vectors1 = Magnitude(\"../MUSE/wiki.multi.en.magnitude\")\n",
    "vectors2 = Magnitude(\"../MUSE/wiki.multi.en.magnitude\")\n",
    "\n",
    "## FUNCTIONS TAKEN FROM https://www.kaggle.com/gmhost/gru-capsule\n",
    "\n",
    "def load_pymag(word_index):\n",
    "#     EMBEDDING_FILE = '../input/quora-insincere-questions-classification/glove.840B.300d/glove.840B.300d.txt'\n",
    "#     def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')[:300]\n",
    "#     embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n",
    "    \n",
    "#     all_embs = np.stack(embeddings_index.values())\n",
    "    emb_mean,emb_std = -0., 0.48782197\n",
    "#     embed_size = all_embs.shape[1]\n",
    "    embed_size = 300\n",
    "\n",
    "    # word_index = tokenizer.word_index\n",
    "    nb_words = min(max_features, len(word_index))\n",
    "    embedding_matrix_ = np.random.normal(emb_mean, emb_std, (nb_words + 1, embed_size))\n",
    "    print(np.shape(embedding_matrix_))\n",
    "    for word, i in tqdm(word_index.items()):\n",
    "        if i >= max_features: continue\n",
    "        elif word in vectors1 and word in vectors2:\n",
    "            embedding_matrix_[i] = np.mean((vectors1.query(word), vectors2.query(word)))\n",
    "        elif word in vectors1:\n",
    "            embedding_matrix_[i] = vectors1.query(word)\n",
    "        elif word in vectors2:\n",
    "            embedding_matrix_[i] = vectors2.query(word)\n",
    "        else:\n",
    "            embedding_matrix_[i] = np.mean((vectors1.query(word), vectors2.query(word)))\n",
    "            \n",
    "    return embedding_matrix_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "7026ee1d913f54dd4b560f654efdb9f833581cd3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def load_glove(word_index):\n",
    "#     EMBEDDING_FILE = '../input/quora-insincere-questions-classification/glove.840B.300d/glove.840B.300d.txt'\n",
    "#     def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')[:300]\n",
    "#     embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n",
    "    \n",
    "#     all_embs = np.stack(embeddings_index.values())\n",
    "#     emb_mean,emb_std = -0.005838499,0.48782197\n",
    "#     embed_size = all_embs.shape[1]\n",
    "\n",
    "#     # word_index = tokenizer.word_index\n",
    "#     nb_words = min(max_features, len(word_index))\n",
    "#     embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "#     for word, i in word_index.items():\n",
    "#         if i >= max_features: continue\n",
    "#         embedding_vector = embeddings_index.get(word)\n",
    "#         if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "#     return embedding_matrix \n",
    "    \n",
    "# def load_fasttext(word_index):    \n",
    "#     EMBEDDING_FILE = '../input/quora-insincere-questions-classification/wiki-news-300d-1M/wiki-news-300d-1M.vec'\n",
    "#     def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "#     embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE) if len(o)>100)\n",
    "\n",
    "#     all_embs = np.stack(embeddings_index.values())\n",
    "#     emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "#     embed_size = all_embs.shape[1]\n",
    "\n",
    "#     # word_index = tokenizer.word_index\n",
    "#     nb_words = min(max_features, len(word_index))\n",
    "#     embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "#     for word, i in word_index.items():\n",
    "#         if i >= max_features: continue\n",
    "#         embedding_vector = embeddings_index.get(word)\n",
    "#         if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "\n",
    "#     return embedding_matrix\n",
    "\n",
    "# def load_para(word_index):\n",
    "#     EMBEDDING_FILE = '../input/quora-insincere-questions-classification/paragram_300_sl999/paragram_300_sl999.txt'\n",
    "#     def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "#     embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE, encoding=\"utf8\", errors='ignore') if len(o)>100)\n",
    "\n",
    "#     all_embs = np.stack(embeddings_index.values())\n",
    "#     emb_mean,emb_std = -0.0053247833,0.49346462\n",
    "#     embed_size = all_embs.shape[1]\n",
    "\n",
    "#     # word_index = tokenizer.word_index\n",
    "#     nb_words = min(max_features, len(word_index))\n",
    "#     embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "#     for word, i in word_index.items():\n",
    "#         if i >= max_features: continue\n",
    "#         embedding_vector = embeddings_index.get(word)\n",
    "#         if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "    \n",
    "#     return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ea10c8e218a1280faa9802bcb7f1117c89ec96f9"
   },
   "source": [
    "## LOAD PROCESSED TRAINING DATA FROM DISK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "173753f0178464d2ba26baf22899884d76d1c83d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../input/ndsc-beginner/train.csv\")\n",
    "df_test = pd.read_csv(\"../input/ndsc-beginner/test.csv\")\n",
    "df = pd.concat([df_train, df_test],sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "0f75559b6fa28c27ecbf145121309378afc884ee",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_vocab(texts):\n",
    "    sentences = texts.apply(lambda x: x.split()).values\n",
    "    vocab = {}\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            try:\n",
    "                vocab[word] += 1\n",
    "            except KeyError:\n",
    "                vocab[word] = 1\n",
    "    return vocab\n",
    "vocab = build_vocab(df['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "5cb425ffbf1f79c1edc4cad3da15a1c1aa53edca",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Sincere questions: 3,772(11.63%) and # Insincere questions: 28,670(88.37%)\n",
      "# Test samples: 172,402(0.259 of train samples)\n"
     ]
    }
   ],
   "source": [
    "sin = len(df_train[df_train[\"Category\"]==0])\n",
    "insin = len(df_train[df_train[\"Category\"]==1])\n",
    "persin = (sin/(sin+insin))*100\n",
    "perinsin = (insin/(sin+insin))*100            \n",
    "print(\"# Sincere questions: {:,}({:.2f}%) and # Insincere questions: {:,}({:.2f}%)\".format(sin,persin,insin,perinsin))\n",
    "# print(\"Sinsere:{}% Insincere: {}%\".format(round(persin,2),round(perinsin,2)))\n",
    "print(\"# Test samples: {:,}({:.3f} of train samples)\".format(len(df_test),len(df_test)/len(df_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "07e9890ec0b490cef57565f7dff953aa56ebd3dc"
   },
   "source": [
    "## Normalization\n",
    "\n",
    "Borrowed from:\n",
    "* How to: Preprocessing when using embeddings\n",
    "https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings\n",
    "* Improve your Score with some Text Preprocessing https://www.kaggle.com/theoviel/improve-your-score-with-some-text-preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "28ebb28ba78972bb8d4fee9b53437045542d20fb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_vocab(texts):\n",
    "    sentences = texts.apply(lambda x: x.split()).values\n",
    "    vocab = {}\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            try:\n",
    "                vocab[word] += 1\n",
    "            except KeyError:\n",
    "                vocab[word] = 1\n",
    "    return vocab\n",
    "\n",
    "def known_contractions(embed):\n",
    "    known = []\n",
    "    for contract in contraction_mapping:\n",
    "        if contract in embed:\n",
    "            known.append(contract)\n",
    "    return known\n",
    "\n",
    "def clean_contractions(text, mapping):\n",
    "    specials = [\"’\", \"‘\", \"´\", \"`\"]\n",
    "    for s in specials:\n",
    "        text = text.replace(s, \"'\")\n",
    "    text = ' '.join([mapping[t] if t in mapping else t for t in text.split(\" \")])\n",
    "    return text\n",
    "\n",
    "def correct_spelling(x, dic):\n",
    "    for word in dic.keys():\n",
    "        x = x.replace(word, dic[word])\n",
    "    return x\n",
    "\n",
    "def unknown_punct(embed, punct):\n",
    "    unknown = ''\n",
    "    for p in punct:\n",
    "        if p not in embed:\n",
    "            unknown += p\n",
    "            unknown += ' '\n",
    "    return unknown\n",
    "\n",
    "def clean_numbers(x):\n",
    "    x = re.sub('[0-9]{5,}', '#####', x)\n",
    "    x = re.sub('[0-9]{4}', '####', x)\n",
    "    x = re.sub('[0-9]{3}', '###', x)\n",
    "    x = re.sub('[0-9]{2}', '##', x)\n",
    "    return x\n",
    "\n",
    "def clean_special_chars(text, punct, mapping):\n",
    "    for p in mapping:\n",
    "        text = text.replace(p, mapping[p])\n",
    "    \n",
    "    for p in punct:\n",
    "        text = text.replace(p, ' {p} ')\n",
    "    \n",
    "    specials = {'\\u200b': ' ', '…': ' ... ', '\\ufeff': '', 'करना': '', 'है': ''}  # Other special characters that I have to deal with in last\n",
    "    for s in specials:\n",
    "        text = text.replace(s, specials[s])\n",
    "    \n",
    "    return text\n",
    "\n",
    "def add_lower(embedding, vocab):\n",
    "    count = 0\n",
    "    for word in vocab:\n",
    "        if word in embedding and word.lower() not in embedding:  \n",
    "            embedding[word.lower()] = embedding[word]\n",
    "            count += 1\n",
    "    print(\"Added {count} words to embedding\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "abeab4c80d6829cf2eae706bfa7929e2871af81f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
    " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
    " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
    " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
    " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
    "\n",
    "def clean_text(x):\n",
    "    x = str(x)\n",
    "    for punct in puncts:\n",
    "        x = x.replace(punct, ' {punct} ')\n",
    "    return x\n",
    "\n",
    "def clean_numbers(x):\n",
    "    x = re.sub('[0-9]{5,}', '#####', x)\n",
    "    x = re.sub('[0-9]{4}', '####', x)\n",
    "    x = re.sub('[0-9]{3}', '###', x)\n",
    "    x = re.sub('[0-9]{2}', '##', x)\n",
    "    return x\n",
    "\n",
    "mispell_dict = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\", 'colour': 'color', 'centre': 'center', 'favourite': 'favorite', 'travelling': 'traveling', 'counselling': 'counseling', 'theatre': 'theater', 'cancelled': 'canceled', 'labour': 'labor', 'organisation': 'organization', 'wwii': 'world war 2', 'citicise': 'criticize', 'youtu ': 'youtube ', 'Qoura': 'Quora', 'sallary': 'salary', 'Whta': 'What', 'narcisist': 'narcissist', 'howdo': 'how do', 'whatare': 'what are', 'howcan': 'how can', 'howmuch': 'how much', 'howmany': 'how many', 'whydo': 'why do', 'doI': 'do I', 'theBest': 'the best', 'howdoes': 'how does', 'mastrubation': 'masturbation', 'mastrubate': 'masturbate', \"mastrubating\": 'masturbating', 'pennis': 'penis', 'Etherium': 'Ethereum', 'narcissit': 'narcissist', 'bigdata': 'big data', '2k17': '2017', '2k18': '2018', 'qouta': 'quota', 'exboyfriend': 'ex boyfriend', 'airhostess': 'air hostess', \"whst\": 'what', 'watsapp': 'whatsapp', 'demonitisation': 'demonetization', 'demonitization': 'demonetization', 'demonetisation': 'demonetization'}\n",
    "\n",
    "def _get_mispell(mispell_dict):\n",
    "    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n",
    "    return mispell_dict, mispell_re\n",
    "\n",
    "mispellings, mispellings_re = _get_mispell(mispell_dict)\n",
    "def replace_typical_misspell(text):\n",
    "    def replace(match):\n",
    "        return mispellings[match.group(0)]\n",
    "    return mispellings_re.sub(replace, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3c09d981ae674e6a373189a04dba8d0932b0765b"
   },
   "source": [
    "Extra feature part taken from https://github.com/wongchunghang/toxic-comment-challenge-lstm/blob/master/toxic_comment_9872_model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "63cb21525251b060aeb309e7be4b48772f8720f5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def add_features(df):\n",
    "    \n",
    "    df['title'] = df['title'].progress_apply(lambda x:str(x))\n",
    "    df['total_length'] = df['title'].progress_apply(len)\n",
    "    df['capitals'] = df['title'].progress_apply(lambda comment: sum(1 for c in comment if c.isupper()))\n",
    "    df['caps_vs_length'] = df.progress_apply(lambda row: float(row['capitals'])/float(row['total_length']),\n",
    "                                axis=1)\n",
    "    df['num_words'] = df.title.str.count('\\S+')\n",
    "    df['num_unique_words'] = df['title'].progress_apply(lambda comment: len(set(w for w in comment.split())))\n",
    "    df['words_vs_unique'] = df['num_unique_words'] / df['num_words']  \n",
    "\n",
    "    return df\n",
    "\n",
    "def load_and_prec():\n",
    "    train_df = pd.read_csv(\"../input/ndsc-beginner/train.csv\")\n",
    "    test_df = pd.read_csv(\"../input/ndsc-beginner/test.csv\")\n",
    "    print(\"Train shape : \",train_df.shape)\n",
    "    print(\"Test shape : \",test_df.shape)\n",
    "    \n",
    "    # lower\n",
    "    train_df[\"title\"] = train_df[\"title\"].progress_apply(lambda x: x.lower())\n",
    "    test_df[\"title\"] = test_df[\"title\"].apply(lambda x: x.lower())\n",
    "\n",
    "    # Clean the text\n",
    "    train_df[\"title\"] = train_df[\"title\"].progress_apply(lambda x: clean_text(x))\n",
    "    test_df[\"title\"] = test_df[\"title\"].apply(lambda x: clean_text(x))\n",
    "    \n",
    "#     # Clean numbers\n",
    "#     train_df[\"title\"] = train_df[\"title\"].progress_apply(lambda x: clean_numbers(x))\n",
    "#     test_df[\"title\"] = test_df[\"title\"].apply(lambda x: clean_numbers(x))\n",
    "    \n",
    "    # Clean spellings\n",
    "    train_df[\"title\"] = train_df[\"title\"].progress_apply(lambda x: replace_typical_misspell(x))\n",
    "    test_df[\"title\"] = test_df[\"title\"].apply(lambda x: replace_typical_misspell(x))\n",
    "    \n",
    "    ## fill up the missing values\n",
    "    train_X = train_df[\"title\"].fillna(\"_##_\").values\n",
    "    test_X = test_df[\"title\"].fillna(\"_##_\").values\n",
    "\n",
    "\n",
    "    \n",
    "    ###################### Add Features ###############################\n",
    "    #  https://github.com/wongchunghang/toxic-comment-challenge-lstm/blob/master/toxic_comment_9872_model.ipynb\n",
    "    train = add_features(train_df)\n",
    "    test = add_features(test_df)\n",
    "\n",
    "    features = train[['caps_vs_length', 'words_vs_unique']].fillna(0)\n",
    "    test_features = test[['caps_vs_length', 'words_vs_unique']].fillna(0)\n",
    "\n",
    "    ss = StandardScaler()\n",
    "    ss.fit(np.vstack((features, test_features)))\n",
    "    features = ss.transform(features)\n",
    "    test_features = ss.transform(test_features)\n",
    "    ###########################################################################\n",
    "\n",
    "    ## Tokenize the sentences\n",
    "    tokenizer = Tokenizer(num_words=max_features)\n",
    "    tokenizer.fit_on_texts(list(train_X))\n",
    "    train_X = tokenizer.texts_to_sequences(train_X)\n",
    "    test_X = tokenizer.texts_to_sequences(test_X)\n",
    "\n",
    "    ## Pad the sentences \n",
    "    train_X = pad_sequences(train_X, maxlen=maxlen)\n",
    "    test_X = pad_sequences(test_X, maxlen=maxlen)\n",
    "\n",
    "    ## Get the Category values\n",
    "    train_y = train_df['Category'].values\n",
    "    \n",
    "#     # Splitting to training and a final test set    \n",
    "#     train_X, x_test_f, train_y, y_test_f = train_test_split(list(zip(train_X,features)), train_y, test_size=0.2, random_state=SEED)    \n",
    "#     train_X, features = zip(*train_X)\n",
    "#     x_test_f, features_t = zip(*x_test_f)    \n",
    "    \n",
    "    #shuffling the data\n",
    "    np.random.seed(SEED)\n",
    "    trn_idx = np.random.permutation(len(train_X))\n",
    "\n",
    "    train_X = train_X[trn_idx]\n",
    "    train_y = train_y[trn_idx]\n",
    "    \n",
    "    return train_X, test_X, train_y, features, test_features, tokenizer.word_index\n",
    "#     return train_X, test_X, train_y, x_test_f,y_test_f,features, test_features, features_t, tokenizer.word_index\n",
    "#     return train_X, test_X, train_y, tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "3c72fcddb4f680879e231c3dbfc0c71e27fc424c",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (666615, 4)\n",
      "Test shape :  (172402, 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a1baa6bffa74af99d4888fd116d0dfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=666615, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4a613f74f4c42c4a0e91bc6c0a145f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=666615, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2828f746dee49dab423ebe57ca9891e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=666615, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7097060a83874c7f8ccb1b72f4be4e0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=666615, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea2176c847ea4159aa2f183606a63ed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=666615, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edd521dc0613460d9cf3e4db411236f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=666615, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba132bf7d3a646b891167bd57f9bfc77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=666615, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4458a763be484e08959e8a545b57c9d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=666615, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96bc58ef79074d9bb61f9340a9b89359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=172402, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27fcf44c04154e2ba14cc063409b5f4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=172402, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37e430328abe4d0ab506a3b895ffde96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=172402, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21678fa89b7645f9b12c4f3cf1c2f0f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=172402, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1777935d085949f7a6d70bd83999b475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=172402, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# fill up the missing values\n",
    "# x_train, x_test, y_train, word_index = load_and_prec()\n",
    "x_train, x_test, y_train, features, test_features, word_index = load_and_prec() \n",
    "# x_train, x_test, y_train, x_test_f,y_test_f,features, test_features,features_t, word_index = load_and_prec() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5264b1a511613e0cb9cffc11e93e906f932be191"
   },
   "source": [
    "### SAVE DATASET TO DISK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory 'ndsc-loaded': File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir ndsc-loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "7dc2704001695c0d691fec74cc111308da3fc340",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.save(\"ndsc-loaded/x_train\",x_train)\n",
    "np.save(\"ndsc-loaded/x_test\",x_test)\n",
    "np.save(\"ndsc-loaded/y_train\",y_train)\n",
    "\n",
    "np.save(\"ndsc-loaded/features\",features)\n",
    "np.save(\"ndsc-loaded/test_features\",test_features)\n",
    "np.save(\"ndsc-loaded/word_index.npy\",word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ef622350c3ac00bcbea516ccf7dffbeca7b4cc39"
   },
   "source": [
    "### LOAD DATASET FROM DISK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "6e1f33f0d744e86cfbcc21b8e696bb568ba1c454",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train = np.load(\"ndsc-loaded/x_train.npy\")\n",
    "x_test = np.load(\"ndsc-loaded/x_test.npy\")\n",
    "y_train = np.load(\"ndsc-loaded/y_train.npy\")\n",
    "features = np.load(\"ndsc-loaded/features.npy\")\n",
    "test_features = np.load(\"ndsc-loaded/test_features.npy\")\n",
    "word_index = np.load(\"ndsc-loaded/word_index.npy\").item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "6db7b1d3f22a6e35699d9f0dbb51343e249d9ee7",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aquarich': 19673,\n",
       " '37634749': 22222,\n",
       " '21349': 15088,\n",
       " 'buln': 9659,\n",
       " '45777': 63371,\n",
       " 'teratur': 3949,\n",
       " 'virginia': 70573,\n",
       " 'motorola': 1227,\n",
       " 'h10fauwegww': 77075,\n",
       " 'menhindari': 36468,\n",
       " 'kuali': 54709,\n",
       " '300ribu': 37137,\n",
       " 'y3nj': 62894,\n",
       " '2200mah': 36703,\n",
       " 'd8d212i': 60121,\n",
       " 'poems': 30883,\n",
       " 'dulue': 24218,\n",
       " 'crg171234': 31369,\n",
       " '083806864057': 21931,\n",
       " 's192k': 79408,\n",
       " 'stwo': 60534,\n",
       " 'fruty': 34245,\n",
       " 'neostrata': 8017,\n",
       " 'kos0059': 45719,\n",
       " '111750': 39161,\n",
       " 'hmt122': 71093,\n",
       " 'exclucive': 40900,\n",
       " 'sofy': 22863,\n",
       " '3h17d': 70191,\n",
       " 'hrb': 58332,\n",
       " 'tarik': 14722,\n",
       " '110k': 23339,\n",
       " '2212': 31916,\n",
       " 'buangett': 74333,\n",
       " 'ofra': 11153,\n",
       " 'trbo': 43802,\n",
       " 'hijabrb': 56790,\n",
       " 'kinclong': 3140,\n",
       " 'css204': 50882,\n",
       " 'layarnya': 72576,\n",
       " '7ml': 2996,\n",
       " 'u002fipod': 79594,\n",
       " '4382eh': 64822,\n",
       " 'shop99': 13164,\n",
       " 'weeks': 36597,\n",
       " 'thinking': 66707,\n",
       " 'matylda': 32860,\n",
       " 'ageloc': 41610,\n",
       " 'fragrant': 17828,\n",
       " 'sevn539': 13621,\n",
       " 'go5': 74103,\n",
       " 'hp14': 26637,\n",
       " 'tretment': 40480,\n",
       " 'p02': 15567,\n",
       " 'vitnage': 31208,\n",
       " 'llb': 54913,\n",
       " 'presse': 43058,\n",
       " 'syahla': 39389,\n",
       " 'outwe': 20690,\n",
       " 'eha': 55650,\n",
       " 'nasa': 1578,\n",
       " 'cova': 68869,\n",
       " 'i5c': 2591,\n",
       " '02540d': 54214,\n",
       " 'ca189': 70061,\n",
       " 'kk17': 58921,\n",
       " 'squeezing': 49336,\n",
       " 'kerawang': 9546,\n",
       " 'gommage': 15884,\n",
       " 'best': 108,\n",
       " 'tbsrbf': 55534,\n",
       " 'yue': 15552,\n",
       " 'boozy': 57909,\n",
       " 'femme': 2804,\n",
       " 'technology': 6692,\n",
       " 'qr0348': 27479,\n",
       " 'dpst': 27228,\n",
       " '5827': 31101,\n",
       " 'kira2': 29410,\n",
       " 'nobox': 17370,\n",
       " 'developer': 22271,\n",
       " '605': 10299,\n",
       " 'ribas': 78766,\n",
       " 'fingerpint': 18565,\n",
       " 'rearcam': 78186,\n",
       " 'mont': 23032,\n",
       " 'tisa': 34083,\n",
       " 'plumper': 7439,\n",
       " 'qr0144': 29511,\n",
       " 'tempting': 31665,\n",
       " '1920x1080': 37417,\n",
       " 'i5': 1674,\n",
       " 'js963': 68435,\n",
       " 'dijamij': 39751,\n",
       " '2878': 47604,\n",
       " 'fojv': 40603,\n",
       " 'xt1805': 74009,\n",
       " 'ekstrakt': 39330,\n",
       " 'abay': 33237,\n",
       " 'bonanza': 34004,\n",
       " 'ce794': 68209,\n",
       " 'seds1069': 50913,\n",
       " 'jribyah': 60815,\n",
       " 'k1470d59': 40099,\n",
       " 'r30': 33812,\n",
       " 'backlit': 37429,\n",
       " 'd025': 31691,\n",
       " 'himeka': 55332,\n",
       " 'erme': 47103,\n",
       " 'softbhd': 72977,\n",
       " 'l0a': 53787,\n",
       " 'z2872': 64141,\n",
       " 'y3ii': 8443,\n",
       " 'rival': 7178,\n",
       " 'cafele': 2638,\n",
       " 'sunnybeauty': 29675,\n",
       " '43045': 32204,\n",
       " 'ca739': 42726,\n",
       " '9t05': 42309,\n",
       " 'x240k': 37299,\n",
       " 'z00ud': 14091,\n",
       " 'sprin': 25155,\n",
       " 'serap': 27995,\n",
       " 'c98': 34731,\n",
       " '800pcs': 40524,\n",
       " 'tbm': 75781,\n",
       " 'knight': 11644,\n",
       " 'ca394': 67006,\n",
       " 'delicare': 27880,\n",
       " '405806': 48929,\n",
       " 'karbar': 74205,\n",
       " '032': 8289,\n",
       " 'national': 3014,\n",
       " 'liptone': 7668,\n",
       " 'geordani': 14216,\n",
       " 'blusas': 2406,\n",
       " 'pb11': 27683,\n",
       " 'miyano': 56448,\n",
       " 'ohm': 21286,\n",
       " '0157': 8209,\n",
       " 'deepblue': 56493,\n",
       " 'qr0607': 45217,\n",
       " 'tebus': 28690,\n",
       " 'louise': 27485,\n",
       " 'berrybelly': 47579,\n",
       " 'waichuan': 52451,\n",
       " 'meer': 49676,\n",
       " '99atte': 47447,\n",
       " 'minew': 17011,\n",
       " 'tc1': 22359,\n",
       " '29215801': 60563,\n",
       " 'lovesilky': 38135,\n",
       " '31086': 58352,\n",
       " 'y4829': 64194,\n",
       " 'sili': 19462,\n",
       " 'cofer': 46042,\n",
       " 'sau': 67487,\n",
       " 'ppa1019': 41251,\n",
       " 'bigmouth': 49831,\n",
       " 'ip6': 9270,\n",
       " 'bab0001': 41410,\n",
       " 'blusing': 38895,\n",
       " 'loo': 8370,\n",
       " 'h9x7': 47782,\n",
       " 'mi55': 77518,\n",
       " 'terbaiik': 31841,\n",
       " 'imel': 54851,\n",
       " 'ardina': 56078,\n",
       " 'redyyy': 48041,\n",
       " 'cod': 1295,\n",
       " 'jakarta': 2014,\n",
       " 'tca': 9403,\n",
       " 'et': 8110,\n",
       " 'oc4': 43439,\n",
       " 'plus7': 75985,\n",
       " 'nng': 52692,\n",
       " 'makep': 28714,\n",
       " 'stabilizer': 14675,\n",
       " 'disko': 9613,\n",
       " 'irix': 51904,\n",
       " 'maimaimiss': 56351,\n",
       " 'calysta': 65937,\n",
       " 'pvd': 69152,\n",
       " 'ls6462': 33949,\n",
       " 'ds1102': 25595,\n",
       " 'correction': 3354,\n",
       " '2oz': 22289,\n",
       " 'beautu': 23713,\n",
       " 'ringan': 1582,\n",
       " 'pertumbuhan': 28033,\n",
       " 'waller': 75365,\n",
       " '63388': 65524,\n",
       " 'alverde': 48140,\n",
       " 'welovedress': 2312,\n",
       " 'me572': 42789,\n",
       " 'overrorec': 22366,\n",
       " 'efek': 3751,\n",
       " 'ss18': 18406,\n",
       " 'd4894': 69039,\n",
       " 'webcam': 35537,\n",
       " 'inventaris': 77990,\n",
       " 'c8815': 73105,\n",
       " 'kr1490': 54389,\n",
       " 'mauna': 31523,\n",
       " 'yanhee': 46148,\n",
       " '43633222': 32814,\n",
       " 'waisted': 4151,\n",
       " 'jkpr29': 28424,\n",
       " 'subwoofer': 36149,\n",
       " 'hou': 33913,\n",
       " 'n90': 72240,\n",
       " 'brandy': 30514,\n",
       " 'stripewhit': 62703,\n",
       " 'zara': 1222,\n",
       " 'g2x': 75260,\n",
       " 'vx1950': 47624,\n",
       " 'underarm': 4905,\n",
       " 'd616h': 79167,\n",
       " '321329': 42711,\n",
       " 'testimonial': 28851,\n",
       " 'or207': 49558,\n",
       " 'd1100': 24978,\n",
       " 'squezee': 29806,\n",
       " 'hunny': 35688,\n",
       " 'higlighter': 6537,\n",
       " 'sd625': 27064,\n",
       " 'detak': 36673,\n",
       " 'k2484': 52022,\n",
       " 'sr06': 30318,\n",
       " 'olivia': 4152,\n",
       " 'qr0486': 17240,\n",
       " 'promo0': 6836,\n",
       " '02a': 8813,\n",
       " '404323': 46773,\n",
       " '27837': 14900,\n",
       " 'livina': 69876,\n",
       " 'step1': 12574,\n",
       " '0941': 40168,\n",
       " 'kyle': 19842,\n",
       " 'ultracover': 10229,\n",
       " 'compression': 17212,\n",
       " 'blazed': 48813,\n",
       " 'memopad': 14179,\n",
       " 'fleur': 10683,\n",
       " 'fahion': 18075,\n",
       " 'csvw': 38201,\n",
       " 'lulus': 23681,\n",
       " 'fucia': 20300,\n",
       " 'buff': 1656,\n",
       " 'sh06f': 35071,\n",
       " 'exposure': 4129,\n",
       " 'susut': 13422,\n",
       " '52id': 73242,\n",
       " 'vztec': 26727,\n",
       " 'du8': 60345,\n",
       " 'rumana': 21026,\n",
       " 'beautybigbang': 14589,\n",
       " 'mmurah': 68737,\n",
       " 'may210': 43282,\n",
       " 'banzai': 28342,\n",
       " 'xiomib': 77827,\n",
       " '21712': 68718,\n",
       " 'w508': 35357,\n",
       " '34652': 60904,\n",
       " 'ca317': 25617,\n",
       " 'qr0473': 17476,\n",
       " 'y65': 1886,\n",
       " 'cj418': 62937,\n",
       " 'visionary': 49888,\n",
       " 'plumming': 48848,\n",
       " 'kintai': 74433,\n",
       " 'lembayung': 53511,\n",
       " 'le170': 74236,\n",
       " '3526': 29936,\n",
       " 'hl801': 53147,\n",
       " 'sk84': 45837,\n",
       " 'release': 3740,\n",
       " 'tf35241': 69790,\n",
       " 'et16': 50319,\n",
       " 'italy': 15945,\n",
       " 'ao13': 42448,\n",
       " 'muze': 36133,\n",
       " 'manon': 26300,\n",
       " 'wavel': 62972,\n",
       " 'mami': 7590,\n",
       " 'instan': 3522,\n",
       " 'tatcha': 39723,\n",
       " 'technical': 25492,\n",
       " 'fof452': 42101,\n",
       " 'perwatan': 11706,\n",
       " '747': 68852,\n",
       " 'naomi': 12732,\n",
       " 'c3219': 66547,\n",
       " 'seds346': 53762,\n",
       " '43682': 24230,\n",
       " 'elega': 11335,\n",
       " 'long': 37,\n",
       " 'pmc104': 70410,\n",
       " 'rvo': 52824,\n",
       " 'gdi': 24703,\n",
       " 'o20': 46919,\n",
       " 'limecrean': 46862,\n",
       " 'beautylist': 29775,\n",
       " 'u2018u2019s': 52974,\n",
       " 'y8a6p': 56251,\n",
       " 'hih': 62034,\n",
       " 'alloy': 6035,\n",
       " 'fox': 6310,\n",
       " '52196db': 55094,\n",
       " '19460': 32867,\n",
       " 'agya': 61016,\n",
       " 'p207': 74694,\n",
       " 'jebuk': 20117,\n",
       " '100271990': 58750,\n",
       " 'longcape': 53194,\n",
       " 'a00pid': 35260,\n",
       " 'ac828': 39001,\n",
       " 'peling': 19127,\n",
       " 'mfg': 23331,\n",
       " 'unifying': 5646,\n",
       " '46706': 56126,\n",
       " 'muluuuus': 72360,\n",
       " 'charter': 13710,\n",
       " 'girdling': 20681,\n",
       " 'evening7': 53000,\n",
       " '1200mah': 27294,\n",
       " 'pewarna': 2662,\n",
       " '081945827245': 18710,\n",
       " '0219': 29202,\n",
       " 'blotted': 17802,\n",
       " '9inci': 75612,\n",
       " 'coverr': 71838,\n",
       " '3047': 63666,\n",
       " 'sku': 8806,\n",
       " 'sahara': 12530,\n",
       " 'grosi': 49187,\n",
       " '20014184': 48573,\n",
       " 'r0258': 47112,\n",
       " 'raynasywa': 54832,\n",
       " 'unp': 65905,\n",
       " 'z8d6': 31637,\n",
       " 'mkp0318067': 48405,\n",
       " '15580': 42852,\n",
       " '35837a': 30381,\n",
       " 'berkerudung': 5067,\n",
       " 'm837860': 57423,\n",
       " 'myg': 22524,\n",
       " 'p57': 33699,\n",
       " 'crg181004': 61528,\n",
       " 'me400cl': 72409,\n",
       " 'alilla': 52520,\n",
       " 'allamanda': 47513,\n",
       " 'selly': 8946,\n",
       " '0pa': 47977,\n",
       " 'tns': 20759,\n",
       " 'relay': 35743,\n",
       " 'shift': 2144,\n",
       " 'fullshet': 3461,\n",
       " '4th': 9597,\n",
       " 'litre': 22735,\n",
       " 'kesukaan': 41866,\n",
       " '3inc': 35759,\n",
       " '1113': 29379,\n",
       " 'armee': 26870,\n",
       " 'capfashion': 32028,\n",
       " 'g6x2': 60848,\n",
       " '22i': 32837,\n",
       " 'ichery': 18987,\n",
       " 'saturday': 16999,\n",
       " 'moisturizer': 807,\n",
       " 'himaya': 37590,\n",
       " 'z8750': 36506,\n",
       " 'xia': 4188,\n",
       " 'tf32733': 52508,\n",
       " 'tampilan': 8606,\n",
       " 'champgne': 47623,\n",
       " '21806': 15067,\n",
       " 'kym15': 53163,\n",
       " '96persen': 38051,\n",
       " '50gr': 1144,\n",
       " 'terrbaik': 20293,\n",
       " 'kimon': 24724,\n",
       " 'qr0210': 17200,\n",
       " 'eyebrom': 40684,\n",
       " 'goyang': 3284,\n",
       " 'berisi': 40809,\n",
       " 'f26': 33537,\n",
       " 'br753': 36649,\n",
       " '00076': 72566,\n",
       " 'sc01': 26813,\n",
       " 'a530f': 21720,\n",
       " 'e2353': 9042,\n",
       " 'd949': 75925,\n",
       " 'cheynn': 71337,\n",
       " 'a30952': 66274,\n",
       " 'karmila': 20617,\n",
       " 'solemio': 10816,\n",
       " 'xfs90026': 61459,\n",
       " 'l9n4': 29332,\n",
       " 'mym': 28154,\n",
       " '7810': 25269,\n",
       " '3486': 51112,\n",
       " 'sh236': 40331,\n",
       " 'mrnlaceup': 51680,\n",
       " 'possing': 38079,\n",
       " 'f23': 67133,\n",
       " '000qid': 76636,\n",
       " 'dlxlwf9yfk10': 77644,\n",
       " 'ps1853': 57528,\n",
       " 'xkdngolf': 61354,\n",
       " 'cottect': 5022,\n",
       " 'roe': 19248,\n",
       " 'aztec': 6970,\n",
       " 'wisqafa': 68740,\n",
       " 'qr0872': 30022,\n",
       " 'skirtb0627': 32986,\n",
       " 'jettttt': 77821,\n",
       " 'b777': 67929,\n",
       " 'bnob': 1484,\n",
       " 'u002fkissbeauty': 23158,\n",
       " 'jala': 2789,\n",
       " 'ht205': 62339,\n",
       " 'chich': 19432,\n",
       " 'j110i': 73976,\n",
       " 'mutu': 2645,\n",
       " 'semata': 6573,\n",
       " 'gerai': 4361,\n",
       " '18a': 11250,\n",
       " '5085': 50497,\n",
       " 'lansun': 72817,\n",
       " 'a30409': 57090,\n",
       " 'mencetak': 5311,\n",
       " 'ewo': 31331,\n",
       " 'blous': 4516,\n",
       " 'satunya': 45236,\n",
       " 'hf9q': 41174,\n",
       " 'belge': 19685,\n",
       " '6846': 32182,\n",
       " 'ing': 4284,\n",
       " '42852': 34753,\n",
       " 'hawwa': 33020,\n",
       " '95mst004611': 53803,\n",
       " '1519': 19713,\n",
       " 'vnaix': 56291,\n",
       " 't100t': 73041,\n",
       " '11609': 28460,\n",
       " 'ab233232': 58274,\n",
       " 'biru': 293,\n",
       " '1ch': 35321,\n",
       " 'eyecon': 29635,\n",
       " '6bqs': 47778,\n",
       " 'jj51': 42150,\n",
       " 'kr4279': 79292,\n",
       " '60393': 34296,\n",
       " 'curl': 12446,\n",
       " 'ristleting': 54953,\n",
       " '17120': 34140,\n",
       " 'mulusz': 74978,\n",
       " 'oi660': 32525,\n",
       " 'n21': 3939,\n",
       " 'blackshark': 7223,\n",
       " 'j775022': 52002,\n",
       " 'na672': 56161,\n",
       " 'elora': 23770,\n",
       " 'qr0652': 30189,\n",
       " 'humphrey': 14558,\n",
       " '81582': 61146,\n",
       " 'dl': 18828,\n",
       " 'seluruh': 1714,\n",
       " '3162': 26747,\n",
       " '45753': 34002,\n",
       " 's8plus': 4736,\n",
       " 'intanse': 17779,\n",
       " 'lipst': 17815,\n",
       " 'positif': 69097,\n",
       " 'airtel': 37375,\n",
       " 'distributorr': 35657,\n",
       " 'wiye': 58313,\n",
       " 'guling': 30360,\n",
       " 'agstus': 73752,\n",
       " 'seny': 48425,\n",
       " 'erhalogy': 8526,\n",
       " 'pqi': 27210,\n",
       " 'pucca': 27488,\n",
       " '6080mah': 27107,\n",
       " '20170808': 74227,\n",
       " 'gemas': 69181,\n",
       " 'sudah': 2232,\n",
       " '541715': 69727,\n",
       " 'joypad': 26504,\n",
       " 'windows8': 77878,\n",
       " 'fs2979': 32677,\n",
       " 'fno': 31517,\n",
       " 'primal': 22553,\n",
       " 'mengurangi': 8262,\n",
       " 'unlined': 25809,\n",
       " 'bm5770': 60083,\n",
       " 'super': 191,\n",
       " 'biore': 2548,\n",
       " 'seds568': 55886,\n",
       " '7048': 70645,\n",
       " 'lipstrick': 48915,\n",
       " 'ariel': 15684,\n",
       " 'lwn': 67875,\n",
       " 'fullsceen': 74041,\n",
       " 'radiancefoundation': 41094,\n",
       " 'luruskan': 23632,\n",
       " 'spacegray': 10418,\n",
       " 'primery': 41549,\n",
       " 'hott': 5523,\n",
       " 'wie': 52455,\n",
       " 'aira': 57756,\n",
       " 'grais': 14155,\n",
       " 'd8rp': 44158,\n",
       " 's5enxt': 35917,\n",
       " 'sweats': 24402,\n",
       " '365': 6042,\n",
       " 'rz09': 21785,\n",
       " 'lgt15ml': 39964,\n",
       " 'kl183': 62318,\n",
       " '50686bk': 55527,\n",
       " 'seumur': 18656,\n",
       " '1015pe': 35367,\n",
       " 'siam': 16216,\n",
       " 'blasers': 56372,\n",
       " 'a354': 48007,\n",
       " 'tinte': 43247,\n",
       " 'palstik': 39115,\n",
       " 'seou': 49456,\n",
       " '43084': 55624,\n",
       " 'w380i': 71428,\n",
       " 'shine': 782,\n",
       " 'primere': 39711,\n",
       " 'ppa': 22653,\n",
       " 'labelle': 16443,\n",
       " '7759': 54194,\n",
       " 'ivy4': 54955,\n",
       " '45633': 58188,\n",
       " 'whi9d': 54453,\n",
       " 'pcc': 22277,\n",
       " '9279': 26171,\n",
       " 'bape': 25530,\n",
       " 'x2hr': 79992,\n",
       " '3laser': 79352,\n",
       " 'ail578': 46114,\n",
       " 'qr0752': 46131,\n",
       " 'lai': 20988,\n",
       " 'qr0718': 30057,\n",
       " 'chetta': 57803,\n",
       " 'bbj01687': 62461,\n",
       " 'bogosipo': 5497,\n",
       " 'obdii': 76129,\n",
       " '0women': 50223,\n",
       " '1631982080': 53445,\n",
       " 'melanox': 5970,\n",
       " 'creammoist': 46956,\n",
       " 'transflucent': 14344,\n",
       " 'sekolahan': 12782,\n",
       " '80539': 69356,\n",
       " '45373': 68885,\n",
       " '23784': 49953,\n",
       " 'bani': 39443,\n",
       " 'set70': 15664,\n",
       " 'odds': 67937,\n",
       " 'clarien': 19921,\n",
       " 'no21': 15495,\n",
       " 'maurice': 21108,\n",
       " 'illite': 38531,\n",
       " 'magazine': 12448,\n",
       " 'oranye': 4434,\n",
       " 'malena': 62193,\n",
       " 'veronni': 9824,\n",
       " 'rahmanto': 37196,\n",
       " 'br10673': 34310,\n",
       " 'orlincojkt': 47555,\n",
       " 'whiteing': 19493,\n",
       " 'akarklopo': 62525,\n",
       " 'iphn': 73195,\n",
       " '45mb': 71248,\n",
       " '256': 924,\n",
       " 'edetion': 35263,\n",
       " '085213330968': 21608,\n",
       " '19564': 20344,\n",
       " '361251': 57009,\n",
       " 'indonnesia': 77973,\n",
       " 'game': 3826,\n",
       " 'sia': 60444,\n",
       " '49j5250': 74806,\n",
       " 'photography': 7509,\n",
       " 'g5w4': 48282,\n",
       " 'l2': 5344,\n",
       " 'ulang': 1547,\n",
       " 'redjellymsglow': 40216,\n",
       " '5553': 13793,\n",
       " 'sack': 17995,\n",
       " 'mariana': 18031,\n",
       " 'kos1033': 38487,\n",
       " 'qr0249': 28155,\n",
       " 'www': 9853,\n",
       " 'lagi': 724,\n",
       " 'benefits': 2067,\n",
       " 'falre': 60885,\n",
       " 'voluminous': 47172,\n",
       " 'a6418': 66693,\n",
       " 'a556uq': 73881,\n",
       " 'minerall': 43208,\n",
       " 'lala': 12096,\n",
       " 'amoma': 33269,\n",
       " 'ana': 8567,\n",
       " 'c230': 36724,\n",
       " 'bx921t': 79084,\n",
       " 'e960': 35351,\n",
       " '594': 30687,\n",
       " '3612': 2021,\n",
       " 'a7d': 36737,\n",
       " 'renang': 3192,\n",
       " 'dopod': 36879,\n",
       " 'ci001k': 29647,\n",
       " 's50k': 4844,\n",
       " '02717': 62985,\n",
       " 'sunplay': 23185,\n",
       " '008': 5395,\n",
       " 'mu': 3344,\n",
       " 'alibaby': 9579,\n",
       " '50e1': 30433,\n",
       " 'zinedine': 75699,\n",
       " '9815': 76147,\n",
       " 'rb2846': 44489,\n",
       " 'lima': 9867,\n",
       " 'ears': 10362,\n",
       " 'zc553kl': 8729,\n",
       " 'cc70p': 48365,\n",
       " 'uncollar': 58364,\n",
       " 'bange': 31952,\n",
       " 'classique': 13302,\n",
       " 'mpv738': 76011,\n",
       " 'z930': 27046,\n",
       " 'xiapmi': 72130,\n",
       " 'boline': 66049,\n",
       " 'lacoste': 2323,\n",
       " 'w8195': 54203,\n",
       " 'jy10': 54433,\n",
       " 'twain': 44483,\n",
       " 'leyla': 70576,\n",
       " 'tabut': 28603,\n",
       " 'loveres': 32614,\n",
       " 'hazelnude': 58572,\n",
       " 'lurs7l': 50079,\n",
       " 'qr0749': 39357,\n",
       " 'icebear2018': 16191,\n",
       " 'communion': 54471,\n",
       " 'hazelineoriginal': 40117,\n",
       " 'd219': 64364,\n",
       " 'y98': 65269,\n",
       " 'marc': 2153,\n",
       " 'diy668': 38484,\n",
       " '7s4': 72300,\n",
       " 'jambang': 8054,\n",
       " 'amuse': 48674,\n",
       " '46181': 34216,\n",
       " 'warnadexinyi': 41368,\n",
       " 'was1': 51114,\n",
       " '3322': 21211,\n",
       " 'r859': 42004,\n",
       " '26853': 59468,\n",
       " 'matira': 33224,\n",
       " 'center': 9144,\n",
       " '6902395491170': 22668,\n",
       " 'kl33': 66025,\n",
       " 'androidmurah': 73157,\n",
       " 'blkg': 4723,\n",
       " 'i4047f': 41661,\n",
       " 'cosoi': 57315,\n",
       " 'sablon': 4073,\n",
       " 'zmn': 11165,\n",
       " 'pebisnis': 37424,\n",
       " 'perempuanwajah': 61216,\n",
       " 'dk32': 36442,\n",
       " 'b2310h21': 36876,\n",
       " 'chanel': 479,\n",
       " 'reversible': 13203,\n",
       " 'gliserin': 38706,\n",
       " 'sb2208': 54171,\n",
       " 'b16c2h': 72080,\n",
       " 'mati': 8141,\n",
       " 'st15i': 75011,\n",
       " 'hhf': 51823,\n",
       " 'tls0298': 47381,\n",
       " '3pilihan': 46289,\n",
       " 'tantop': 25571,\n",
       " 'alin': 31295,\n",
       " 'stephenoh': 23425,\n",
       " '3087': 75461,\n",
       " 'pakek': 23564,\n",
       " 'games': 13804,\n",
       " 'twmffc567': 52716,\n",
       " 'n9095': 49882,\n",
       " 'horse': 4368,\n",
       " 'bg': 4801,\n",
       " 'd6': 34803,\n",
       " '1484f': 64756,\n",
       " 'lovita': 63510,\n",
       " 'b170': 75308,\n",
       " '34356': 21367,\n",
       " 'e951': 48891,\n",
       " '093': 46988,\n",
       " '31626': 48831,\n",
       " 'angie': 16440,\n",
       " 'm76': 52839,\n",
       " 'ruje': 45550,\n",
       " 'napolly': 44410,\n",
       " 't19': 72759,\n",
       " 'shinchan': 46629,\n",
       " 'redminote3': 77392,\n",
       " 'gbl489': 47347,\n",
       " 'monggo': 5976,\n",
       " 'glowidskincare': 41681,\n",
       " 'k461': 31304,\n",
       " 'tukatuku': 70648,\n",
       " 'lampu': 3840,\n",
       " 'g3121': 18971,\n",
       " 'gjqz9': 55574,\n",
       " '4343': 72998,\n",
       " 'danela': 31960,\n",
       " '50n': 71046,\n",
       " 'ihh': 18126,\n",
       " 'x540bp': 78444,\n",
       " 'pigme': 5656,\n",
       " 'tonight': 40145,\n",
       " 'dyed': 17778,\n",
       " '17576': 53382,\n",
       " 'j6786': 31636,\n",
       " 'ucin': 44271,\n",
       " '16d1ht': 34982,\n",
       " 'bland': 29493,\n",
       " 'lotiin': 46228,\n",
       " 'justige': 37288,\n",
       " 'cellumination': 4207,\n",
       " '1932': 29000,\n",
       " 'ail831': 40792,\n",
       " '3125': 67412,\n",
       " 'q2807': 52952,\n",
       " '77lovecom': 77490,\n",
       " 'chatt': 19057,\n",
       " 'blouson': 50091,\n",
       " 'i851o': 71728,\n",
       " 'ihatethebluesdeadmoon': 65732,\n",
       " 'swy': 61618,\n",
       " 'j295': 63702,\n",
       " '1195': 34249,\n",
       " '30114': 60506,\n",
       " 'gb0284': 31625,\n",
       " '00006': 70563,\n",
       " 'hadia': 10744,\n",
       " 'overshadow': 16965,\n",
       " 'elvis': 20772,\n",
       " '042cs20839': 77508,\n",
       " 'g355h': 13974,\n",
       " 'ina': 25284,\n",
       " 'gampang': 30420,\n",
       " 'yogya': 12582,\n",
       " 'an1': 59257,\n",
       " 'delying': 47457,\n",
       " '2jt': 71412,\n",
       " 'coating': 7303,\n",
       " 'mtf': 17967,\n",
       " 'u002fultrathin': 35185,\n",
       " 'foundtaion': 28453,\n",
       " 'bbq': 12390,\n",
       " 'foral': 20561,\n",
       " '1248': 24158,\n",
       " 'blam': 10678,\n",
       " 'froal': 66007,\n",
       " 'clean': 705,\n",
       " 'qr0247': 28877,\n",
       " 'menjuntai': 24250,\n",
       " '32666846301': 63965,\n",
       " 'hnya': 79177,\n",
       " 'tf32673': 55759,\n",
       " 'bibtka': 33614,\n",
       " 'jinnee': 55399,\n",
       " 'bvlgari': 14485,\n",
       " '0205': 29213,\n",
       " 'nini': 33777,\n",
       " 'kos2303': 45053,\n",
       " 'teddies': 18171,\n",
       " '33191': 49633,\n",
       " 'mounted': 24707,\n",
       " 'vivov5plus': 71226,\n",
       " 'bulat': 1047,\n",
       " 'oppoo': 36965,\n",
       " 'a85': 50366,\n",
       " 'perlak': 76847,\n",
       " '409077': 49384,\n",
       " 'service': 11463,\n",
       " 'hopylovy': 26018,\n",
       " 'grns': 13013,\n",
       " '4p': 11775,\n",
       " 'korset': 5510,\n",
       " 'senza': 32235,\n",
       " 'kobeinc': 65635,\n",
       " '220038': 50068,\n",
       " 'komedogenik': 41401,\n",
       " 'damaged': 23387,\n",
       " 'airchushion': 42616,\n",
       " 'kiandra': 54729,\n",
       " 'andra': 61145,\n",
       " '1080m': 74945,\n",
       " 'lips809': 48177,\n",
       " 'concealear': 5937,\n",
       " 'dstn': 51493,\n",
       " 'oss': 9987,\n",
       " 'heflashor': 32091,\n",
       " '83800': 6231,\n",
       " 'homebutton': 78032,\n",
       " 'acnedarm': 22876,\n",
       " 'ligh': 7432,\n",
       " 'dupe': 6680,\n",
       " 'sp77': 44076,\n",
       " '26935bk': 60134,\n",
       " 'fitbit': 8492,\n",
       " 'striped': 622,\n",
       " 'refurbh': 71677,\n",
       " '22138': 33315,\n",
       " 'fj': 25376,\n",
       " 'lmmo341': 48130,\n",
       " 'navigasi': 27147,\n",
       " 'pilot': 24132,\n",
       " 'biyan': 32874,\n",
       " 'br10674': 18488,\n",
       " 'sebuah': 9196,\n",
       " '1378': 29204,\n",
       " 'ab232901': 24653,\n",
       " '9890': 31831,\n",
       " 'snowise': 3652,\n",
       " 'jaguart': 54099,\n",
       " '1202': 74376,\n",
       " 'swisse': 41068,\n",
       " 'cocktai': 14853,\n",
       " 'pdo': 68973,\n",
       " 'tangga': 17430,\n",
       " 'qr0455': 38807,\n",
       " '70mm': 21759,\n",
       " 'mdrskin': 46943,\n",
       " 'yvv': 55815,\n",
       " 'ix': 27167,\n",
       " 'hargasatuan': 39636,\n",
       " 'qr0404': 47472,\n",
       " 'gfor': 76984,\n",
       " 'g4n2': 48954,\n",
       " 'memangkas': 31644,\n",
       " 'wingbra': 59588,\n",
       " 'detok': 23154,\n",
       " '2245009817795': 59318,\n",
       " 'a0131k': 50502,\n",
       " 'ch4nel': 58042,\n",
       " 'cigarettes': 77445,\n",
       " 'koleksihijab1': 70633,\n",
       " 'xy1135': 75845,\n",
       " 'baal': 23665,\n",
       " 'e470': 36087,\n",
       " 'rivet': 6327,\n",
       " 'ashinta': 54047,\n",
       " 'peonygarden': 73196,\n",
       " 'y1996': 45478,\n",
       " '7856': 13645,\n",
       " 'eunby': 18034,\n",
       " '8710': 7711,\n",
       " 'bonie': 39033,\n",
       " 'sund': 70413,\n",
       " 'cni1171': 46499,\n",
       " 'champ': 7666,\n",
       " 'joward': 58820,\n",
       " 'kafftan': 53652,\n",
       " 'berlebih': 12361,\n",
       " 'wt01268': 53437,\n",
       " 'peiyen': 5380,\n",
       " '6460': 65034,\n",
       " 'lourence': 45693,\n",
       " '083136936111': 26582,\n",
       " 'a7b': 35234,\n",
       " 'prosumer': 21883,\n",
       " 'g307': 67690,\n",
       " 'f3215': 21900,\n",
       " '88242w': 51894,\n",
       " 'hrsgen1111': 15558,\n",
       " 'micel': 63696,\n",
       " 'otr': 32758,\n",
       " 'mat4': 49011,\n",
       " 'ennd': 56970,\n",
       " 'ga411t': 78980,\n",
       " 'talc3574': 48872,\n",
       " 'breeze': 22928,\n",
       " 'xstream': 16849,\n",
       " 'qr0443': 27741,\n",
       " 'n72': 27159,\n",
       " 'stock': 121,\n",
       " 'protections': 37945,\n",
       " 'bn42': 74761,\n",
       " 'coffe': 13326,\n",
       " 'mmf': 20058,\n",
       " 'kinkoo': 72017,\n",
       " '24gri': 42892,\n",
       " 'l9345': 67512,\n",
       " 'universwlle': 46645,\n",
       " 'fcd': 8874,\n",
       " 'siku': 3591,\n",
       " '5130': 4297,\n",
       " 'airqushion': 46461,\n",
       " 'huarache': 31410,\n",
       " 'bs251': 66534,\n",
       " 'sk29': 44626,\n",
       " '97': 2956,\n",
       " 'pk': 9735,\n",
       " 'perjalanan': 8357,\n",
       " 'kei': 70730,\n",
       " 'butir': 8557,\n",
       " 'qr0262': 40491,\n",
       " 'fhd': 2745,\n",
       " 'gemuk': 6974,\n",
       " 'net': 1853,\n",
       " 'x3196': 54673,\n",
       " 'frv': 77136,\n",
       " '22962': 16043,\n",
       " 'cucigu8dang': 75147,\n",
       " 'tototro': 70521,\n",
       " 'teli': 50975,\n",
       " '8507': 75216,\n",
       " 'nyanyi': 20371,\n",
       " 'kissfull': 22511,\n",
       " 'elsh': 17251,\n",
       " 'jumbo': 314,\n",
       " 'female': 522,\n",
       " 'toming': 52226,\n",
       " 'kos1429': 27857,\n",
       " '189180': 31838,\n",
       " '082190725241': 74391,\n",
       " '4139': 4541,\n",
       " '19817': 25301,\n",
       " '081230280234': 74387,\n",
       " 'kos133': 43199,\n",
       " 'slip': 2440,\n",
       " '13088': 33794,\n",
       " 'be74': 47913,\n",
       " '23sand': 43582,\n",
       " 'aperture': 34910,\n",
       " '804': 15506,\n",
       " 'mattelast': 17799,\n",
       " 'i10': 3710,\n",
       " 'cloths': 66265,\n",
       " 'yte': 53367,\n",
       " '7649': 30611,\n",
       " 'levi': 24575,\n",
       " '996f': 51565,\n",
       " 'px360': 18719,\n",
       " '8394': 67761,\n",
       " '2th': 5464,\n",
       " 'excuisite': 9816,\n",
       " 'welovet': 7717,\n",
       " 'pld32t1500': 34985,\n",
       " 'boohoo': 52374,\n",
       " '20180206': 62775,\n",
       " 'juicer': 14709,\n",
       " 'ds67': 54783,\n",
       " 'fushi': 28344,\n",
       " '3756': 4163,\n",
       " 'sbtwc2': 17528,\n",
       " 'r23': 17155,\n",
       " 'fed': 19363,\n",
       " 'summmer': 32282,\n",
       " 'yasmin': 24956,\n",
       " '24': 1019,\n",
       " 'lah002': 49728,\n",
       " 'hilliter': 44325,\n",
       " 'o407': 76111,\n",
       " 'xba': 12929,\n",
       " 'b2006': 25941,\n",
       " 'serba': 1212,\n",
       " '185101': 30890,\n",
       " 'kigsmardishop28': 16138,\n",
       " 'ilite': 9302,\n",
       " 'gari': 25993,\n",
       " '800d': 26045,\n",
       " 'coolad': 71988,\n",
       " 'jumpsuits': 4573,\n",
       " 'tempel': 6315,\n",
       " 'berbahaya': 16975,\n",
       " 'judy': 61911,\n",
       " 'bah': 58007,\n",
       " 'rahaya': 36547,\n",
       " 'cj564': 67697,\n",
       " 'fans': 15018,\n",
       " 'qr0590': 19634,\n",
       " 'mac085': 22844,\n",
       " '2layar': 36147,\n",
       " 'w618735': 56447,\n",
       " '18457': 52056,\n",
       " 'kru': 13633,\n",
       " '20013530': 43151,\n",
       " '1new': 21463,\n",
       " ...}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e5c51a8329d569d13b9f0369ebb98ca8e2e55440"
   },
   "source": [
    "### Load Embeddings\n",
    "\n",
    "Two embedding matrices have been used. Glove, and paragram. The mean of the two is used as the final embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "6a5f4502324d369ff6faa3692accee4f8a233005",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80066, 300)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f380dc7130344f8846f1e04fdb3cee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=80065), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(80066, 300)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing entries in the embedding are set using np.random.normal so we have to seed here too\n",
    "# seed_everything()\n",
    "\n",
    "# glove_embeddings = load_glove(word_index)\n",
    "paragram_embeddings = load_pymag(word_index)\n",
    "\n",
    "# embedding_matrix = np.mean([glove_embeddings, paragram_embeddings], axis=0)\n",
    "embedding_matrix = paragram_embeddings\n",
    "\n",
    "# vocab = build_vocab(df['title'])\n",
    "# add_lower(embedding_matrix, vocab)\n",
    "# del glove_embeddings, paragram_embeddings\n",
    "del paragram_embeddings\n",
    "gc.collect()\n",
    "\n",
    "np.shape(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "2484f29f159af679af7d7745e522221e31e42ce0"
   },
   "outputs": [],
   "source": [
    "np.save(\"ndsc-loaded/embedding_matrix.npy\",embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.load(\"ndsc-loaded/embedding_matrix.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(666615, 100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,  160,    5,  134,  125,\n",
       "         423],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0, 1981,  510,   64,  792, 1091,  158,  230,  213,\n",
       "         217]], dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.shape(x_train))\n",
    "x_train[:2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(666615,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 2, 15])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.shape(y_train))\n",
    "y_train[:2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(172402, 100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0, 2519,  129,   70,    5,   15,   53,  215,\n",
       "        1084],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,  122,  312,  281,  292,  143,  345,   15,    5,   53,\n",
       "         685]], dtype=int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.shape(x_test))\n",
    "x_test[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(666615, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.       , 0.1507402],\n",
       "       [0.       , 0.1507402]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.shape(features))\n",
    "features[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(172402, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.       , 0.1507402],\n",
       "       [0.       , 0.1507402]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.shape(test_features))\n",
    "test_features[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "80065\n",
      "('aquarich', 19673)\n",
      "{}\n",
      "{}\n",
      "{'punct': 1}\n",
      "{'q6d8': 48861}\n",
      "{'d1n1': 48862}\n",
      "162\n",
      "3498\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(type(word_index))\n",
    "print(len(word_index))\n",
    "print(list(word_index.items())[0])\n",
    "print({k:v for k, v in word_index.items() if v == 0})\n",
    "print({k:v for k, v in word_index.items() if v == -1})\n",
    "print({k:v for k, v in word_index.items() if v == 1})\n",
    "print({k:v for k, v in word_index.items() if v == 48861})\n",
    "print({k:v for k, v in word_index.items() if v == 48862})\n",
    "print(word_index[\"a\"])\n",
    "print(word_index[\"pikachu\"])\n",
    "print(word_index[\"1\"])\n",
    "# print(word_index[\"uberxxxLLL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80066, 300)\n",
      "80065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 4.76878300e-01, -2.73604039e-01, -5.81318289e-01, ...,\n",
       "         1.69410268e-01, -4.14568587e-01, -3.89041583e-02],\n",
       "       [-4.20845269e-03, -4.20845269e-03, -4.20845269e-03, ...,\n",
       "        -4.20845269e-03, -4.20845269e-03, -4.20845269e-03],\n",
       "       [-2.34678015e-05, -2.34678015e-05, -2.34678015e-05, ...,\n",
       "        -2.34678015e-05, -2.34678015e-05, -2.34678015e-05],\n",
       "       ...,\n",
       "       [-7.76812239e-04, -7.76812239e-04, -7.76812239e-04, ...,\n",
       "        -7.76812239e-04, -7.76812239e-04, -7.76812239e-04],\n",
       "       [-1.77667101e-03, -1.77667101e-03, -1.77667101e-03, ...,\n",
       "        -1.77667101e-03, -1.77667101e-03, -1.77667101e-03],\n",
       "       [ 2.46250474e-03,  2.46250474e-03,  2.46250474e-03, ...,\n",
       "         2.46250474e-03,  2.46250474e-03,  2.46250474e-03]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.shape(embedding_matrix))\n",
    "print(len(word_index)) # i don't understand why different\n",
    "embedding_matrix[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE TOKENISER ENDS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d3b707858357eec18403f97368a40c43987b40e8"
   },
   "source": [
    "### Use Stratified K Fold to improve results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fa55c64890964220ded1762236e091e59e502e53",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "splits = list(StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED).split(x_train, y_train))\n",
    "splits[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0d60b4b08c9cf86d7d4dac80be1dd184004f84d1"
   },
   "outputs": [],
   "source": [
    "splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9b8854b696e53c4bc7ee31849478c933bd94f080"
   },
   "outputs": [],
   "source": [
    "np.shape(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8098bea0cee9117ff9dc4e11feba53e49b80cb55"
   },
   "source": [
    "### Cyclic CLR\n",
    "Code taken from https://www.kaggle.com/dannykliu/lstm-with-attention-clr-in-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9d531a7454923f90d0e7443b1ed1373d008c2e88",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# code inspired from: https://github.com/anandsaha/pytorch.cyclic.learning.rate/blob/master/cls.py\n",
    "class CyclicLR(object):\n",
    "    def __init__(self, optimizer, base_lr=1e-3, max_lr=6e-3,\n",
    "                 step_size=2000, mode='triangular', gamma=1.,\n",
    "                 scale_fn=None, scale_mode='cycle', last_batch_iteration=-1):\n",
    "\n",
    "        if not isinstance(optimizer, Optimizer):\n",
    "            raise TypeError('{} is not an Optimizer'.format(\n",
    "                type(optimizer).__name__))\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        if isinstance(base_lr, list) or isinstance(base_lr, tuple):\n",
    "            if len(base_lr) != len(optimizer.param_groups):\n",
    "                raise ValueError(\"expected {} base_lr, got {}\".format(\n",
    "                    len(optimizer.param_groups), len(base_lr)))\n",
    "            self.base_lrs = list(base_lr)\n",
    "        else:\n",
    "            self.base_lrs = [base_lr] * len(optimizer.param_groups)\n",
    "\n",
    "        if isinstance(max_lr, list) or isinstance(max_lr, tuple):\n",
    "            if len(max_lr) != len(optimizer.param_groups):\n",
    "                raise ValueError(\"expected {} max_lr, got {}\".format(\n",
    "                    len(optimizer.param_groups), len(max_lr)))\n",
    "            self.max_lrs = list(max_lr)\n",
    "        else:\n",
    "            self.max_lrs = [max_lr] * len(optimizer.param_groups)\n",
    "\n",
    "        self.step_size = step_size\n",
    "\n",
    "        if mode not in ['triangular', 'triangular2', 'exp_range'] \\\n",
    "                and scale_fn is None:\n",
    "            raise ValueError('mode is invalid and scale_fn is None')\n",
    "\n",
    "        self.mode = mode\n",
    "        self.gamma = gamma\n",
    "\n",
    "        if scale_fn is None:\n",
    "            if self.mode == 'triangular':\n",
    "                self.scale_fn = self._triangular_scale_fn\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'triangular2':\n",
    "                self.scale_fn = self._triangular2_scale_fn\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'exp_range':\n",
    "                self.scale_fn = self._exp_range_scale_fn\n",
    "                self.scale_mode = 'iterations'\n",
    "        else:\n",
    "            self.scale_fn = scale_fn\n",
    "            self.scale_mode = scale_mode\n",
    "\n",
    "        self.batch_step(last_batch_iteration + 1)\n",
    "        self.last_batch_iteration = last_batch_iteration\n",
    "\n",
    "    def batch_step(self, batch_iteration=None):\n",
    "        if batch_iteration is None:\n",
    "            batch_iteration = self.last_batch_iteration + 1\n",
    "        self.last_batch_iteration = batch_iteration\n",
    "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "    def _triangular_scale_fn(self, x):\n",
    "        return 1.\n",
    "\n",
    "    def _triangular2_scale_fn(self, x):\n",
    "        return 1 / (2. ** (x - 1))\n",
    "\n",
    "    def _exp_range_scale_fn(self, x):\n",
    "        return self.gamma**(x)\n",
    "\n",
    "    def get_lr(self):\n",
    "        step_size = float(self.step_size)\n",
    "        cycle = np.floor(1 + self.last_batch_iteration / (2 * step_size))\n",
    "        x = np.abs(self.last_batch_iteration / step_size - 2 * cycle + 1)\n",
    "\n",
    "        lrs = []\n",
    "        param_lrs = zip(self.optimizer.param_groups, self.base_lrs, self.max_lrs)\n",
    "        for param_group, base_lr, max_lr in param_lrs:\n",
    "            base_height = (max_lr - base_lr) * np.maximum(0, (1 - x))\n",
    "            if self.scale_mode == 'cycle':\n",
    "                lr = base_lr + base_height * self.scale_fn(cycle)\n",
    "            else:\n",
    "                lr = base_lr + base_height * self.scale_fn(self.last_batch_iteration)\n",
    "            lrs.append(lr)\n",
    "        return lrs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b8caecb207a12d4a5524fe16e4524b31c7da8bac"
   },
   "source": [
    "### Model Architecture\n",
    "\n",
    "Binary LSTM with an attention layer and an additional fully connected layer. Also added extra features taken from a winning kernel of the toxic comments competition. Also using CLR and a capsule Layer. Blended together in concatentation.\n",
    "\n",
    "Initial idea borrowed from: https://www.kaggle.com/ziliwang/baseline-pytorch-bilstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8f7e1d15451201efbac2741b03d4b0dfd3b9bfe0"
   },
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "embedding_dim = 300\n",
    "embedding_path = '../save/embedding_matrix.npy'  # or False, not use pre-trained-matrix\n",
    "use_pretrained_embedding = True\n",
    "\n",
    "hidden_size = 60\n",
    "gru_len = hidden_size\n",
    "\n",
    "Routings = 4 #5\n",
    "Num_capsule = 5\n",
    "Dim_capsule = 5#16\n",
    "dropout_p = 0.25\n",
    "rate_drop_dense = 0.28\n",
    "LR = 0.001\n",
    "T_epsilon = 1e-7\n",
    "num_classes = 30\n",
    "\n",
    "\n",
    "class Embed_Layer(nn.Module):\n",
    "    def __init__(self, embedding_matrix=None, vocab_size=None, embedding_dim=300):\n",
    "        super(Embed_Layer, self).__init__()\n",
    "        self.encoder = nn.Embedding(vocab_size + 1, embedding_dim)\n",
    "        if use_pretrained_embedding:\n",
    "            # self.encoder.weight.data.copy_(t.from_numpy(np.load(embedding_path))) # 方法一，加载np.save的npy文件\n",
    "            self.encoder.weight.data.copy_(t.from_numpy(embedding_matrix))  # 方法二\n",
    "\n",
    "    def forward(self, x, dropout_p=0.25):\n",
    "        return nn.Dropout(p=dropout_p)(self.encoder(x))\n",
    "\n",
    "\n",
    "class GRU_Layer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GRU_Layer, self).__init__()\n",
    "        self.gru = nn.GRU(input_size=300,\n",
    "                          hidden_size=gru_len,\n",
    "                          bidirectional=True)\n",
    "        '''\n",
    "        自己修改GRU里面的激活函数及加dropout和recurrent_dropout\n",
    "        如果要使用，把rnn_revised import进来，但好像是使用cpu跑的，比较慢\n",
    "       '''\n",
    "        # # if you uncomment /*from rnn_revised import * */, uncomment following code aswell\n",
    "        # self.gru = RNNHardSigmoid('GRU', input_size=300,\n",
    "        #                           hidden_size=gru_len,\n",
    "        #                           bidirectional=True)\n",
    "\n",
    "    # 这步很关键，需要像keras一样用glorot_uniform和orthogonal_uniform初始化参数\n",
    "    def init_weights(self):\n",
    "        ih = (param.data for name, param in self.named_parameters() if 'weight_ih' in name)\n",
    "        hh = (param.data for name, param in self.named_parameters() if 'weight_hh' in name)\n",
    "        b = (param.data for name, param in self.named_parameters() if 'bias' in name)\n",
    "        for k in ih:\n",
    "            nn.init.xavier_uniform_(k)\n",
    "        for k in hh:\n",
    "            nn.init.orthogonal_(k)\n",
    "        for k in b:\n",
    "            nn.init.constant_(k, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gru(x)\n",
    "\n",
    "\n",
    "# core caps_layer with squash func\n",
    "class Caps_Layer(nn.Module):\n",
    "    def __init__(self, input_dim_capsule=gru_len * 2, num_capsule=Num_capsule, dim_capsule=Dim_capsule, \\\n",
    "                 routings=Routings, kernel_size=(9, 1), share_weights=True,\n",
    "                 activation='default', **kwargs):\n",
    "        super(Caps_Layer, self).__init__(**kwargs)\n",
    "\n",
    "        self.num_capsule = num_capsule\n",
    "        self.dim_capsule = dim_capsule\n",
    "        self.routings = routings\n",
    "        self.kernel_size = kernel_size  # 暂时没用到\n",
    "        self.share_weights = share_weights\n",
    "        if activation == 'default':\n",
    "            self.activation = self.squash\n",
    "        else:\n",
    "            self.activation = nn.ReLU(inplace=True)\n",
    "\n",
    "        if self.share_weights:\n",
    "            self.W = nn.Parameter(\n",
    "                nn.init.xavier_normal_(t.empty(1, input_dim_capsule, self.num_capsule * self.dim_capsule)))\n",
    "        else:\n",
    "            self.W = nn.Parameter(\n",
    "                t.randn(BATCH_SIZE, input_dim_capsule, self.num_capsule * self.dim_capsule))  # 64即batch_size\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        if self.share_weights:\n",
    "            u_hat_vecs = t.matmul(x, self.W)\n",
    "        else:\n",
    "            print('add later')\n",
    "\n",
    "        batch_size = x.size(0)\n",
    "        input_num_capsule = x.size(1)\n",
    "        u_hat_vecs = u_hat_vecs.view((batch_size, input_num_capsule,\n",
    "                                      self.num_capsule, self.dim_capsule))\n",
    "        u_hat_vecs = u_hat_vecs.permute(0, 2, 1, 3)  # 转成(batch_size,num_capsule,input_num_capsule,dim_capsule)\n",
    "        b = t.zeros_like(u_hat_vecs[:, :, :, 0])  # (batch_size,num_capsule,input_num_capsule)\n",
    "\n",
    "        for i in range(self.routings):\n",
    "            b = b.permute(0, 2, 1)\n",
    "            c = F.softmax(b, dim=2)\n",
    "            c = c.permute(0, 2, 1)\n",
    "            b = b.permute(0, 2, 1)\n",
    "            outputs = self.activation(t.einsum('bij,bijk->bik', (c, u_hat_vecs)))  # batch matrix multiplication\n",
    "            # outputs shape (batch_size, num_capsule, dim_capsule)\n",
    "            if i < self.routings - 1:\n",
    "                b = t.einsum('bik,bijk->bij', (outputs, u_hat_vecs))  # batch matrix multiplication\n",
    "        return outputs  # (batch_size, num_capsule, dim_capsule)\n",
    "\n",
    "    # text version of squash, slight different from original one\n",
    "    def squash(self, x, axis=-1):\n",
    "        s_squared_norm = (x ** 2).sum(axis, keepdim=True)\n",
    "        scale = t.sqrt(s_squared_norm + T_epsilon)\n",
    "        return x / scale\n",
    "    \n",
    "class Capsule_Main(nn.Module):\n",
    "    def __init__(self, embedding_matrix=None, vocab_size=None):\n",
    "        super(Capsule_Main, self).__init__()\n",
    "        self.embed_layer = Embed_Layer(embedding_matrix, vocab_size)\n",
    "        self.gru_layer = GRU_Layer()\n",
    "        # 【重要】初始化GRU权重操作，这一步非常关键，acc上升到0.98，如果用默认的uniform初始化则acc一直在0.5左右\n",
    "        self.gru_layer.init_weights()\n",
    "        self.caps_layer = Caps_Layer()\n",
    "        self.dense_layer = Dense_Layer()\n",
    "\n",
    "    def forward(self, content):\n",
    "        content1 = self.embed_layer(content)\n",
    "        content2, _ = self.gru_layer(\n",
    "            content1)  # 这个输出是个tuple，一个output(seq_len, batch_size, num_directions * hidden_size)，一个hn\n",
    "        content3 = self.caps_layer(content2)\n",
    "        output = self.dense_layer(content3)\n",
    "        return output\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "170b27f66c7e546d8e84c79357d40f86c6b1ec42",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, feature_dim, step_dim, bias=True, **kwargs):\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "        \n",
    "        self.supports_masking = True\n",
    "\n",
    "        self.bias = bias\n",
    "        self.feature_dim = feature_dim\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        \n",
    "        weight = torch.zeros(feature_dim, 1)\n",
    "        nn.init.xavier_uniform_(weight)\n",
    "        self.weight = nn.Parameter(weight)\n",
    "        \n",
    "        if bias:\n",
    "            self.b = nn.Parameter(torch.zeros(step_dim))\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        feature_dim = self.feature_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = torch.mm(\n",
    "            x.contiguous().view(-1, feature_dim), \n",
    "            self.weight\n",
    "        ).view(-1, step_dim)\n",
    "        \n",
    "        if self.bias:\n",
    "            eij = eij + self.b\n",
    "            \n",
    "        eij = torch.tanh(eij)\n",
    "        a = torch.exp(eij)\n",
    "        \n",
    "        if mask is not None:\n",
    "            a = a * mask\n",
    "\n",
    "        a = a / torch.sum(a, 1, keepdim=True) + 1e-10\n",
    "\n",
    "        weighted_input = x * torch.unsqueeze(a, -1)\n",
    "        return torch.sum(weighted_input, 1)\n",
    "    \n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        \n",
    "        fc_layer = 16\n",
    "        fc_layer1 = 16\n",
    "\n",
    "        self.embedding = nn.Embedding(max_features, embed_size)\n",
    "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        \n",
    "        self.embedding_dropout = nn.Dropout2d(0.1)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, bidirectional=True, batch_first=True)\n",
    "        self.gru = nn.GRU(hidden_size * 2, hidden_size, bidirectional=True, batch_first=True)\n",
    "\n",
    "        self.lstm2 = nn.LSTM(hidden_size * 2, hidden_size, bidirectional=True, batch_first=True)\n",
    "\n",
    "        self.lstm_attention = Attention(hidden_size * 2, maxlen)\n",
    "        self.gru_attention = Attention(hidden_size * 2, maxlen)\n",
    "        \n",
    "        self.linear = nn.Linear(hidden_size*8+34, fc_layer1) #643:80 - 483:60 - 323:40\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc = nn.Linear(fc_layer**2,fc_layer)\n",
    "        self.out = nn.Linear(fc_layer, 1)\n",
    "        self.lincaps = nn.Linear(Num_capsule * Dim_capsule, 32)\n",
    "        self.caps_layer = Caps_Layer()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "#         Capsule(num_capsule=10, dim_capsule=10, routings=4, share_weights=True)(x)\n",
    "\n",
    "        h_embedding = self.embedding(x[0])\n",
    "        h_embedding = torch.squeeze(\n",
    "            self.embedding_dropout(torch.unsqueeze(h_embedding, 0)))\n",
    "        \n",
    "        h_lstm, _ = self.lstm(h_embedding)\n",
    "        h_gru, _ = self.gru(h_lstm)\n",
    "\n",
    "        ##Capsule Layer        \n",
    "        content3 = self.caps_layer(h_gru)\n",
    "        content3 = self.dropout(content3)\n",
    "        batch_size = content3.size(0)\n",
    "        content3 = content3.view(batch_size, -1)\n",
    "        content3 = self.relu(self.lincaps(content3))\n",
    "\n",
    "        ##Attention Layer\n",
    "        h_lstm_atten = self.lstm_attention(h_lstm)\n",
    "        h_gru_atten = self.gru_attention(h_gru)\n",
    "        \n",
    "        # global average pooling\n",
    "        avg_pool = torch.mean(h_gru, 1)\n",
    "        # global max pooling\n",
    "        max_pool, _ = torch.max(h_gru, 1)\n",
    "        \n",
    "        f = torch.tensor(x[1], dtype=torch.float).cuda()\n",
    "\n",
    "                #[512,160]\n",
    "        conc = torch.cat((h_lstm_atten, h_gru_atten,content3, avg_pool, max_pool,f), 1)\n",
    "        conc = self.relu(self.linear(conc))\n",
    "        conc = self.dropout(conc)\n",
    "\n",
    "        out = self.out(conc)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e4e47597cde552a41cdd8ec2531aa6a861e491ae"
   },
   "source": [
    "### Training\n",
    "\n",
    "The method is borrowed from https://www.kaggle.com/hengzheng/pytorch-starter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0c6339acdc14e6688ed47e9f439e81cd7cfca57f"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# matrix for the out-of-fold predictions\n",
    "train_preds = np.zeros((len(x_train)))\n",
    "# matrix for the predictions on the test set\n",
    "test_preds = np.zeros((len(df_test)))\n",
    "\n",
    "# always call this before training for deterministic results\n",
    "seed_everything()\n",
    "\n",
    "# x_test_cuda_f = torch.tensor(x_test_f, dtype=torch.long).cuda()\n",
    "# test_f = torch.utils.data.TensorDataset(x_test_cuda_f)\n",
    "# test_loader_f = torch.utils.data.DataLoader(test_f, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "x_test_cuda = torch.tensor(x_test, dtype=torch.long).cuda()\n",
    "test = torch.utils.data.TensorDataset(x_test_cuda)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "avg_losses_f = []\n",
    "avg_val_losses_f = []\n",
    "print('Time elapsed : {}'.format(start_time_-time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2cfdd46b117a11af54ed01f1f9511782e50a00fa",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, (train_idx, valid_idx) in enumerate(splits):    \n",
    "    # split data in train / validation according to the KFold indeces\n",
    "    # also, convert them to a torch tensor and store them on the GPU (done with .cuda())\n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "    features = np.array(features)\n",
    "\n",
    "    x_train_fold = torch.tensor(x_train[train_idx.astype(int)], dtype=torch.long).cuda()\n",
    "    y_train_fold = torch.tensor(y_train[train_idx.astype(int), np.newaxis], dtype=torch.float32).cuda()\n",
    "    \n",
    "    kfold_X_features = features[train_idx.astype(int)]\n",
    "    kfold_X_valid_features = features[valid_idx.astype(int)]\n",
    "    x_val_fold = torch.tensor(x_train[valid_idx.astype(int)], dtype=torch.long).cuda()\n",
    "    y_val_fold = torch.tensor(y_train[valid_idx.astype(int), np.newaxis], dtype=torch.float32).cuda()\n",
    "    \n",
    "#     model = BiLSTM(lstm_layer=2,hidden_dim=40,dropout=DROPOUT).cuda()\n",
    "    model = NeuralNet()\n",
    "\n",
    "    # make sure everything in the model is running on the GPU\n",
    "    model.cuda()\n",
    "\n",
    "    # define binary cross entropy loss\n",
    "    # note that the model returns logit to take advantage of the log-sum-exp trick \n",
    "    # for numerical stability in the loss\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss(reduction='sum')\n",
    "\n",
    "    step_size = 300\n",
    "    base_lr, max_lr = 0.001, 0.003   \n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), \n",
    "                             lr=max_lr)\n",
    "    \n",
    "    ################################################################################################\n",
    "    scheduler = CyclicLR(optimizer, base_lr=base_lr, max_lr=max_lr,\n",
    "               step_size=step_size, mode='exp_range',\n",
    "               gamma=0.99994)\n",
    "    scheduler = None\n",
    "    ###############################################################################################\n",
    "\n",
    "    train = torch.utils.data.TensorDataset(x_train_fold, y_train_fold)\n",
    "    valid = torch.utils.data.TensorDataset(x_val_fold, y_val_fold)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    print(f'Fold {i + 1}')\n",
    "    for epoch in range(n_epochs):\n",
    "        # set train mode of the model. This enables operations which are only applied during training like dropout\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "\n",
    "        avg_loss = 0.  \n",
    "        for i, (x_batch, y_batch) in enumerate(train_loader):\n",
    "            # Forward pass: compute predicted y by passing x to the model.\n",
    "            ################################################################################################            \n",
    "            f = kfold_X_features[i * batch_size:(i+1) * batch_size]\n",
    "            y_pred = model([x_batch,f])\n",
    "            ################################################################################################\n",
    "\n",
    "            ################################################################################################\n",
    "\n",
    "            if scheduler:\n",
    "                scheduler.batch_step()\n",
    "            ################################################################################################\n",
    "\n",
    "\n",
    "            # Compute and print loss.\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "\n",
    "            # Before the backward pass, use the optimizer object to zero all of the\n",
    "            # gradients for the Tensors it will update (which are the learnable weights\n",
    "            # of the model)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "\n",
    "            # Calling the step function on an Optimizer makes an update to its parameters\n",
    "            optimizer.step()\n",
    "            avg_loss += loss.item() / len(train_loader)\n",
    "            \n",
    "        # set evaluation mode of the model. This disabled operations which are only applied during training like dropout\n",
    "        model.eval()\n",
    "        \n",
    "        # predict all the samples in y_val_fold batch per batch\n",
    "        valid_preds_fold = np.zeros((x_val_fold.size(0)))\n",
    "        test_preds_fold = np.zeros((len(df_test)))\n",
    "        \n",
    "        avg_val_loss = 0.\n",
    "        for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
    "            f = kfold_X_valid_features[i * batch_size:(i+1) * batch_size]            \n",
    "            y_pred = model([x_batch,f]).detach()\n",
    "            \n",
    "            avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
    "            valid_preds_fold[i * batch_size:(i+1) * batch_size] = sigmoid(y_pred.cpu().numpy())[:, 0]\n",
    "        \n",
    "        elapsed_time = time.time() - start_time \n",
    "        print('Epoch {}/{} \\t loss={:.4f} \\t val_loss={:.4f} \\t time={:.2f}s'.format(\n",
    "            epoch + 1, n_epochs, avg_loss, avg_val_loss, elapsed_time))\n",
    "    avg_losses_f.append(avg_loss)\n",
    "    avg_val_losses_f.append(avg_val_loss) \n",
    "    # predict all samples in the test set batch per batch\n",
    "    for i, (x_batch,) in enumerate(test_loader):\n",
    "        f = test_features[i * batch_size:(i+1) * batch_size]\n",
    "        y_pred = model([x_batch,f]).detach()\n",
    "\n",
    "        test_preds_fold[i * batch_size:(i+1) * batch_size] = sigmoid(y_pred.cpu().numpy())[:, 0]\n",
    "        \n",
    "    train_preds[valid_idx] = valid_preds_fold\n",
    "    test_preds += test_preds_fold / len(splits)\n",
    "\n",
    "print('All \\t loss={:.4f} \\t val_loss={:.4f} \\t '.format(np.average(avg_losses_f),np.average(avg_val_losses_f)))\n",
    "\n",
    "# x_train, x_test_f, y_train, y_test_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1d2187d4bbf48350eaf365b6dd8b027d5be69e0c"
   },
   "source": [
    "### Find final Thresshold\n",
    "\n",
    "Borrowed from: https://www.kaggle.com/ziliwang/baseline-pytorch-bilstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dc4a4c681294ba06526fed4e871cfe8639cf25e4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def bestThresshold(y_train,train_preds):\n",
    "    # since we know that the function in concave\n",
    "    bd = (0.0, 0.5, 1.0) # left, middle, right\n",
    "    val = (0.0, f1_score(y_train, np.array(train_preds)>bd[1]), 0.0)\n",
    "    for _ in tqdm(range(20)):\n",
    "        left_mid = 0.5*(bd[0]+bd[1])\n",
    "        right_mid = 0.5*(bd[1]+bd[2])\n",
    "        left_mid_val = f1_score(y_train, np.array(train_preds)>left_mid)\n",
    "        right_mid_val = f1_score(y_train, np.array(train_preds)>right_mid)\n",
    "        if left_mid_val > right_mid_val:\n",
    "            bd = (bd[0], left_mid, bd[1])\n",
    "            print('when threshold is {:.6f}, F1 score is {:.6f}'.format(bd[1], left_mid_val))\n",
    "        else:\n",
    "            bd = (bd[1], right_mid, bd[2])\n",
    "            print('when threshold is {:.6f}, F1 score is {:.6f}'.format(bd[1], right_mid_val))\n",
    "    return bd[1]\n",
    "\n",
    "delta = bestThresshold(y_train,train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d17dd7b0a92ec98134bf8996fd210edaadf7bed6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Time elapsed : {}'.format(start_time_-time.time()))\n",
    "submission = df_test[['qid']].copy()\n",
    "submission['prediction'] = (test_preds > delta).astype(int)\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a1a07a65e47b5dcefaac040f3f633dc077e8f61e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!head submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "877e136bff87b72486555718acb4255c4a2b6d7c"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
