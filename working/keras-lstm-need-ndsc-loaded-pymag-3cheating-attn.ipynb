{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8499d29f81fcdce9470988906c7ddbddf80c1674"
   },
   "outputs": [],
   "source": [
    "# major errors, please make it work for baseline again\n",
    "# issue might be due to embeddings\n",
    "# troubleshooting because the results don't make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "21f85dfd5b9bf3d8b27ba29149d52253e5d64049"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7704fa4894773088894d27a4919018c0b69dfb23"
   },
   "outputs": [],
   "source": [
    "x_train_full = np.load(\"../input/ndscloaded/x_train.npy\")\n",
    "y_train_full = np.load(\"../input/ndscloaded/y_train.npy\")\n",
    "x_test_full = np.load(\"../input/ndscloaded/x_test.npy\")\n",
    "features = np.load(\"../input/ndscloaded/features.npy\")\n",
    "test_features = np.load(\"../input/ndscloaded/test_features.npy\")\n",
    "word_index = np.load(\"../input/ndscloaded/word_index.npy\").item()\n",
    "embedding_matrix = np.load(\"../input/ndscloaded/embedding_matrix.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1a7922512e47a6d4583ce9223f1598dc1f8784b3"
   },
   "outputs": [],
   "source": [
    "print(np.shape(x_train_full))\n",
    "print(x_train_full)\n",
    "print(np.shape(y_train_full))\n",
    "print(y_train_full)\n",
    "print(np.shape(x_test_full))\n",
    "print(x_test_full)\n",
    "print(np.shape(embedding_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cbae94aa49d2e9fc546170e3e7aa70e7e25533a1"
   },
   "outputs": [],
   "source": [
    "# batch_size = 128\n",
    "\n",
    "# indices = np.arange(len(x_train_full))\n",
    "# # np.random.shuffle(indices)\n",
    "# i = 0\n",
    "# x_train_batch_tokens = np.take(x_train_full, indices[i*batch_size:(i+1)*batch_size], axis = 0) \n",
    "# x_train_batch = [[embedding_matrix[token] for token in title][::-1] for title in x_train_batch_tokens]\n",
    "# # [::-1] because I want it back in the correct order\n",
    "# y_train_batch_targets = np.take(y_train_full, indices[i*batch_size:(i+1)*batch_size])\n",
    "# y_train_batch = np.zeros((batch_size, 58))\n",
    "# y_train_batch[np.arange(batch_size), y_train_batch_targets] = 1\n",
    "\n",
    "# print(indices)\n",
    "# print(x_train_batch_tokens)\n",
    "# print(np.shape(x_train_batch))\n",
    "# print(y_train_batch_targets)\n",
    "# print(y_train_batch)\n",
    "\n",
    "# print(type(indices))\n",
    "# print(type(x_train_batch_tokens))\n",
    "# print(type(np.shape(x_train_batch[:1])))\n",
    "# print(type(x_train_batch))\n",
    "# print(type(y_train_batch_targets))\n",
    "# print(type(y_train_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f0594b597eec1bc125c3dc24bedf3e2df2a5ecbe"
   },
   "outputs": [],
   "source": [
    "import pandas as cv\n",
    "test_df = pd.read_csv(\"../input/ndsc-beginner/test.csv\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d3b234f8886b73137955c03adda9c64b722fe628"
   },
   "source": [
    "# Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "41da1b7ffcf76b7f8e7e7f2d491624e5cfe81c85"
   },
   "outputs": [],
   "source": [
    "!ls ../input/ndscindexes/ndscindexes\n",
    "!ls ../input/ndscindexes/ndscindexes/trn_index/\n",
    "!ls ../input/ndscindexes/ndscindexes/trn_index/face/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ef9b98937b0ba47c53207d258eb0d304b79ede0d"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# c for face\n",
    "trn_index_np_c = glob.glob(\"../input/ndscindexes/ndscindexes/trn_index/face/*\")  \n",
    "val_index_np_c = glob.glob(\"../input/ndscindexes/ndscindexes/val_index/face/*\") \n",
    "\n",
    "trn_index_c = np.concatenate([np.load(i) for i in trn_index_np_c]).ravel()\n",
    "val_index_c = np.concatenate([np.load(i) for i in val_index_np_c]).ravel()\n",
    "\n",
    "# l for lips\n",
    "trn_index_np_l = glob.glob(\"../input/ndscindexes/ndscindexes/trn_index/lip/*\")\n",
    "val_index_np_l = glob.glob(\"../input/ndscindexes/ndscindexes/val_index/lip/*\")\n",
    "\n",
    "trn_index_l = np.concatenate([np.load(i) for i in trn_index_np_l]).ravel()\n",
    "val_index_l = np.concatenate([np.load(i) for i in val_index_np_l]).ravel()\n",
    "\n",
    "# b for beauty (combined) \n",
    "trn_index_b = np.concatenate([trn_index_c,trn_index_l]).ravel()\n",
    "val_index_b = np.concatenate([val_index_c,val_index_l]).ravel()\n",
    "tes_index_b = np.argwhere(test_df[\"image_path\"].str[0] == \"b\").ravel()\n",
    "\n",
    "# f for fashion\n",
    "trn_index_np_f = glob.glob(\"../input/ndscindexes/ndscindexes/trn_index/fashion/*\")\n",
    "val_index_np_f = glob.glob(\"../input/ndscindexes/ndscindexes/val_index/fashion/*\")\n",
    "\n",
    "trn_index_f = np.concatenate([np.load(i) for i in trn_index_np_f]).ravel()\n",
    "val_index_f = np.concatenate([np.load(i) for i in val_index_np_f]).ravel()\n",
    "tes_index_f = np.argwhere(test_df[\"image_path\"].str[0] == \"f\").ravel()\n",
    "\n",
    "# m for mobile\n",
    "trn_index_np_m = glob.glob(\"../input/ndscindexes/ndscindexes/trn_index/mobile/*\")\n",
    "val_index_np_m = glob.glob(\"../input/ndscindexes/ndscindexes/val_index/mobile/*\")\n",
    "\n",
    "trn_index_m = np.concatenate([np.load(i) for i in trn_index_np_m]).ravel()\n",
    "val_index_m = np.concatenate([np.load(i) for i in val_index_np_m]).ravel()\n",
    "tes_index_m = np.argwhere(test_df[\"image_path\"].str[0] == \"m\").ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0be61b8645023c9f87c2973ed4fa7f692fe1c045"
   },
   "outputs": [],
   "source": [
    "print(np.shape(trn_index_b))\n",
    "print(np.shape(trn_index_f))\n",
    "print(np.shape(trn_index_m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ec24e9b17e3bfdd2a7f434a1ff0a5f8414f688ac"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1efaf9e756e747f51add1127f979b724a2cc2d12"
   },
   "outputs": [],
   "source": [
    "from keras.models import Model, clone_model\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import CuDNNLSTM, Dense, Bidirectional, Activation, Input, Dropout\n",
    "from keras.layers import Permute, Reshape, concatenate, Flatten\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Input, CuDNNLSTM, Dense, Bidirectional, Activation, Flatten, RepeatVector, Permute\n",
    "from keras.layers import merge\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1c777661eeee57f4905225424dee88e2dc8ceb9c"
   },
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Bidirectional(CuDNNLSTM(64, return_sequences=True),\n",
    "# #                         input_shape=(100, 300)\n",
    "#                         input_shape=(100, 300)\n",
    "#                        ))\n",
    "# model.add(Bidirectional(CuDNNLSTM(64)))\n",
    "# model.add(Dense(58))\n",
    "# model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7f7e43e1927f5bed8d06bb16e6759d1049b282f6"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = 300\n",
    "TIME_STEPS = 100\n",
    "# if True, the attention vector is shared across the input_dimensions where the attention is applied.\n",
    "SINGLE_ATTENTION_VECTOR = False\n",
    "\n",
    "def attention_3d_block(inputs):\n",
    "    # inputs.shape = (batch_size, time_steps, input_dim)\n",
    "    input_dim = int(inputs.shape[2])\n",
    "    a = Permute((2, 1))(inputs)\n",
    "    a = Reshape((input_dim, TIME_STEPS))(a) # this line is not useful. It's just to know which dimension is what.\n",
    "    a = Dense(TIME_STEPS, activation='softmax')(a)\n",
    "    if SINGLE_ATTENTION_VECTOR:\n",
    "        a = Lambda(lambda x: K.mean(x, axis=1), name='dim_reduction')(a)\n",
    "        a = RepeatVector(input_dim)(a)\n",
    "    a_probs = Permute((2, 1), name='attention_vec')(a)\n",
    "    output_attention_mul = concatenate([inputs, a_probs])\n",
    "    return output_attention_mul\n",
    "\n",
    "inputs_embed = Input((TIME_STEPS, INPUT_DIM))\n",
    "\n",
    "lstm_1 = CuDNNLSTM(64, return_sequences=True)(inputs_embed)\n",
    "lstm_2 = CuDNNLSTM(64, return_sequences=True)(lstm_1)\n",
    "\n",
    "attention = attention_3d_block(lstm_2)\n",
    "attention = Flatten()(attention)\n",
    "\n",
    "fc_layer = Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01))(attention)\n",
    "fc_layer = BatchNormalization()(fc_layer)\n",
    "fc_layer = Dropout(0.2)(fc_layer)\n",
    "outputs = Dense(58, activation='softmax')(fc_layer)\n",
    "\n",
    "x_val = np.take(x_train_full, val_index_b, axis = 0)\n",
    "y_val = np.take(y_train_full, val_index_b, axis = 0)\n",
    "\n",
    "model = Model(inputs=inputs_embed, outputs=outputs)\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              validation_data=(x_val, y_val),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a730749b06bcc5f9ac50788e88953925bfabb8de"
   },
   "outputs": [],
   "source": [
    "# Data providers\n",
    "batch_size = 128\n",
    "\n",
    "# print(len(x_train))  # note that x_train is no longer constant, same with y_train\n",
    "# print(np.random.shuffle())\n",
    "\n",
    "def batch_gen():\n",
    "    indices = np.arange(len(x_train)-1)\n",
    "    n_batches = math.floor(len(x_train) / batch_size)\n",
    "    while True: \n",
    "        np.random.shuffle(indices)  # Shuffle the data.\n",
    "        for i in range(n_batches):\n",
    "            x_train_batch_tokens = np.take(x_train, indices[i*batch_size:(i+1)*batch_size], axis = 0) \n",
    "            x_train_batch = [[embedding_matrix[token] for token in title][::-1] for title in x_train_batch_tokens]\n",
    "            # [::-1] because I want it back in the correct order\n",
    "            y_train_batch_targets = np.take(y_train, indices[i*batch_size:(i+1)*batch_size])\n",
    "#             y_train_batch = np.zeros((batch_size, 58))\n",
    "#             y_train_batch[np.arange(batch_size), y_train_batch_targets] = 1\n",
    "            yield (np.array(x_train_batch), y_train_batch_targets)\n",
    "            \n",
    "mg = batch_gen()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "997da9517f6832aee421826fffe7da0e705bf7fc"
   },
   "source": [
    "# Training for model BEAUTY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3d742c12cd90ca522cb4e31c3c9843e70b74518d"
   },
   "outputs": [],
   "source": [
    "print(np.shape(x_val))\n",
    "print(np.shape(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8744d59760390dc6a1fc6de282dce6584e7c2837"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "x_train = np.take(x_train_full, trn_index_b, axis = 0)\n",
    "y_train = np.take(y_train_full, trn_index_b, axis = 0)\n",
    "print(np.shape(x_train))\n",
    "print(np.shape(y_train))\n",
    "x_val_tokens = np.take(x_train_full, val_index_b, axis = 0)[:10000]\n",
    "x_val = np.array([[embedding_matrix[token] for token in title][::-1] for title in x_val_tokens])\n",
    "y_val = np.take(y_train_full, val_index_b, axis = 0)[:10000]\n",
    "print(np.shape(x_val))\n",
    "print(np.shape(y_val))\n",
    "model_beauty = keras.models.clone_model(model)\n",
    "model_beauty.set_weights(model.get_weights())\n",
    "model_beauty.compile(optimizer='adam', \n",
    "                     loss='sparse_categorical_crossentropy', \n",
    "                     metrics=['accuracy'])\n",
    "mg = batch_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "42eecb0eaa0603fc030d873d869bd2aecc096e7a"
   },
   "outputs": [],
   "source": [
    "model_beauty.fit_generator(mg, epochs=20,\n",
    "                           steps_per_epoch=1000,\n",
    "                           validation_data=(x_val, y_val),\n",
    "                           verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b280be36a83c101574dd9a4224682ed896802c4a"
   },
   "outputs": [],
   "source": [
    "model_beauty.fit_generator(mg, epochs=2,\n",
    "                           steps_per_epoch=1000,\n",
    "                           validation_data=(x_val, y_val),\n",
    "                           verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2a57b8b4bc2c337865a15c9958d057df2791f22c"
   },
   "source": [
    "# Training for model FASHION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1f80d6626eb9b57c8ee7f0441404df744c4bcf19"
   },
   "outputs": [],
   "source": [
    "x_train = np.take(x_train_full, trn_index_f, axis = 0)\n",
    "y_train = np.take(y_train_full, trn_index_f, axis = 0)\n",
    "print(np.shape(x_train))\n",
    "print(np.shape(y_train))\n",
    "x_val_tokens = np.take(x_train_full, val_index_f, axis = 0)[:10000]\n",
    "x_val = np.array([[embedding_matrix[token] for token in title][::-1] for title in x_val_tokens])\n",
    "y_val = np.take(y_train_full, val_index_f, axis = 0)[:10000]\n",
    "print(np.shape(x_val))\n",
    "print(np.shape(y_val))\n",
    "model_fashion = keras.models.clone_model(model)\n",
    "model_fashion.set_weights(model.get_weights())\n",
    "model_fashion.compile(optimizer='adam', \n",
    "                     loss='sparse_categorical_crossentropy', \n",
    "                     metrics=['accuracy'])\n",
    "mg = batch_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9b5d810327980605f01ba3c9847494670fc48c24"
   },
   "outputs": [],
   "source": [
    "model_fashion.fit_generator(mg, epochs=20,\n",
    "                           steps_per_epoch=1000,\n",
    "                           validation_data=(x_val, y_val),\n",
    "                           verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d713063697183eb031240cc5350627634e70a3fc"
   },
   "outputs": [],
   "source": [
    "model_fashion.fit_generator(mg, epochs=2,\n",
    "                           steps_per_epoch=1000,\n",
    "                           validation_data=(x_val, y_val),\n",
    "                           verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "524f2632ef886bbea550c9c8df63e42382954d85"
   },
   "source": [
    "# Training for model MOBILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ce4410456beb6985bdbd44950f8eecabc570905b"
   },
   "outputs": [],
   "source": [
    "x_train = np.take(x_train_full, trn_index_m, axis = 0)\n",
    "y_train = np.take(y_train_full, trn_index_m, axis = 0)\n",
    "print(np.shape(x_train))\n",
    "print(np.shape(y_train))\n",
    "x_val_tokens = np.take(x_train_full, val_index_m, axis = 0)[:10000]\n",
    "x_val = np.array([[embedding_matrix[token] for token in title][::-1] for title in x_val_tokens])\n",
    "y_val = np.take(y_train_full, val_index_m, axis = 0)[:10000]\n",
    "print(np.shape(x_val))\n",
    "print(np.shape(y_val))\n",
    "model_mobile = keras.models.clone_model(model)\n",
    "model_mobile.set_weights(model.get_weights())\n",
    "model_mobile.compile(optimizer='adam', \n",
    "                     loss='sparse_categorical_crossentropy', \n",
    "                     metrics=['accuracy'])\n",
    "mg = batch_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0b289bbab5e079b6c5a27ff070721de34adf3bba"
   },
   "outputs": [],
   "source": [
    "model_mobile.fit_generator(mg, epochs=20,\n",
    "                           steps_per_epoch=1000,\n",
    "                           validation_data=(x_val, y_val),\n",
    "                           verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3d0c569e788ac6788aa3788f79ad0360db6f4d24"
   },
   "outputs": [],
   "source": [
    "model_mobile.fit_generator(mg, epochs=2,\n",
    "                           steps_per_epoch=1000,\n",
    "                           validation_data=(x_val, y_val),\n",
    "                           verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d6cdda0e301be0b84e826e29f0f3a85c41aa6da9"
   },
   "source": [
    "# VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f5617cf99c45ed7c17d02c95ddc414c393d0c5a9"
   },
   "outputs": [],
   "source": [
    "del x_val  # running of memory :(\n",
    "del y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4c906ed670984f8d56936a4cb5f15191bc31853b"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "# prediction part\n",
    "batch_size = 128\n",
    "def batch_gen():\n",
    "    n_batches = math.ceil(len(x_test) / batch_size)\n",
    "    for i in range(n_batches):\n",
    "        x_test_batch_tokens = x_test[i*batch_size:(i+1)*batch_size]\n",
    "        x_test_batch = [[embedding_matrix[token] for token in title][::-1] for title in x_test_batch_tokens]\n",
    "        # [::-1] because I want it back in the correct order\n",
    "        yield np.array(x_test_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e7b02aa639e4090799550687f560f198394b1b45"
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"../input/ndsc-beginner/test.csv\")\n",
    "test_df[\"Supercategory\"] = test_df[\"image_path\"].str[0]\n",
    "supercats = np.array(test_df[\"Supercategory\"])\n",
    "supercat_dict = {\n",
    "    \"b\" : np.array([1]*17 + [0]*14 + [0]*27),\n",
    "    \"f\" : np.array([0]*17 + [1]*14 + [0]*27),\n",
    "    \"m\" : np.array([0]*17 + [0]*14 + [1]*27)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4f7544284890ef583abaa7f6e185b39eec2177f7"
   },
   "outputs": [],
   "source": [
    "x_test = np.take(x_train_full, val_index_b, axis = 0)\n",
    "y_test = np.take(y_train_full, val_index_b, axis = 0)\n",
    "preds_beauty_val = []\n",
    "for x in batch_gen():\n",
    "    preds_beauty_val.extend(model_beauty.predict(x))\n",
    "correct_beauty_val = np.sum(np.equal(y_test, [np.argmax(pred) for pred in preds_beauty_val]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "db4570878deb831d8d0b6130e782891b7ef1ffe6"
   },
   "outputs": [],
   "source": [
    "x_test = np.take(x_train_full, val_index_f, axis = 0)\n",
    "y_test = np.take(y_train_full, val_index_f, axis = 0)\n",
    "preds_fashion_val = []\n",
    "for x in batch_gen():\n",
    "    preds_fashion_val.extend(model_fashion.predict(x))\n",
    "correct_fashion_val = np.sum(np.equal(y_test, [np.argmax(pred) for pred in preds_fashion_val]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ad6d29cc4f09a2aad1c3cca1e6206adcc8f3a9b3"
   },
   "outputs": [],
   "source": [
    "x_test = np.take(x_train_full, val_index_m, axis = 0)\n",
    "y_test = np.take(y_train_full, val_index_m, axis = 0)\n",
    "preds_mobile_val = []\n",
    "for x in batch_gen():\n",
    "    preds_mobile_val.extend(model_mobile.predict(x))\n",
    "correct_mobile_val = np.sum(np.equal(y_test, [np.argmax(pred) for pred in preds_mobile_val]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1b0399662fdb3a3e13d76dc9e6d219a79eeecdf1"
   },
   "outputs": [],
   "source": [
    "correct_total_val = correct_beauty_val + correct_fashion_val + correct_mobile_val\n",
    "total_val_entries = len(preds_beauty_val) + len(preds_fashion_val) + len(preds_mobile_val)\n",
    "\n",
    "print(\"beauty : \", correct_beauty_val, \"/\", len(preds_beauty_val), \n",
    "      \"{:5f}\".format(correct_beauty_val/len(preds_beauty_val)))\n",
    "print(\"fashion : \", correct_fashion_val, \"/\", len(preds_fashion_val), \n",
    "      \"{:5f}\".format(correct_fashion_val/len(preds_fashion_val)))\n",
    "print(\"mobile : \", correct_mobile_val, \"/\", len(preds_mobile_val), \n",
    "      \"{:5f}\".format(correct_mobile_val/len(preds_mobile_val)))\n",
    "print(\"total : \", correct_total_val, \"/\", total_val_entries, \n",
    "      \"{:5f}\".format(correct_total_val/total_val_entries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "23210c1eed51b797786675fe039e0ade3302f366"
   },
   "source": [
    "# INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "197e1b3f42a69aa2525e0983f1ee07b93e29fdfa"
   },
   "outputs": [],
   "source": [
    "x_test = np.take(x_test_full, tes_index_b, axis = 0)\n",
    "preds_beauty = []\n",
    "for x in batch_gen():\n",
    "    preds_beauty.extend(model_beauty.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e363bb145758905cccad7abca520d23fd4012c2b"
   },
   "outputs": [],
   "source": [
    "x_test = np.take(x_test_full, tes_index_f, axis = 0)\n",
    "preds_fashion = []\n",
    "for x in batch_gen():\n",
    "    preds_fashion.extend(model_fashion.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "303a0dd7cf525d9267947b2b6c31233d70abe4e2"
   },
   "outputs": [],
   "source": [
    "x_test = np.take(x_test_full, tes_index_m, axis = 0)\n",
    "preds_mobile = []\n",
    "for x in batch_gen():\n",
    "    preds_mobile.extend(model_mobile.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a2630dbbaddad6187cdb53c137e99d07f986f0d6"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(preds_beauty[0])\n",
    "plt.plot(preds_fashion[0])\n",
    "plt.plot(preds_mobile[0])\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4f7bf2795530cd93021ed7532d37d67c8cbf7a1a"
   },
   "outputs": [],
   "source": [
    "all_preds = [\"None\"]*len(x_test_full)\n",
    "\n",
    "for i,x in zip(tes_index_b,preds_beauty):\n",
    "    all_preds[i] = x\n",
    "for i,x in zip(tes_index_f,preds_fashion):\n",
    "    all_preds[i] = x\n",
    "for i,x in zip(tes_index_m,preds_mobile):\n",
    "    all_preds[i] = x\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "print(np.shape(all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bd8c4d0b41e11f7d02f7e41f486682b1586dc712"
   },
   "outputs": [],
   "source": [
    "print(np.shape(all_preds))\n",
    "y_te = [np.argmax(pred) for pred,supercat in zip(all_preds,supercats)]\n",
    "\n",
    "submit_df = pd.DataFrame({\"itemid\": test_df[\"itemid\"], \"Category\": y_te})\n",
    "submit_df.to_csv(\"submission_no_cheat.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ba26a17316a19e765e1037e1748bab507cc476d6"
   },
   "outputs": [],
   "source": [
    "print(np.shape(all_preds))\n",
    "y_te = [np.argmax(pred*supercat_dict[supercat]) for pred,supercat in zip(all_preds,supercats)]\n",
    "\n",
    "submit_df = pd.DataFrame({\"itemid\": test_df[\"itemid\"], \"Category\": y_te})\n",
    "submit_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "09d5f33d035ba739dd446f4cba3e8d5ccecf528c"
   },
   "outputs": [],
   "source": [
    "submit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d5661fe6c3125ea78bff6f351873cee9fc6ace48"
   },
   "outputs": [],
   "source": [
    "submit_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5370268d2ca2e6ba238ad47968db54164167b425"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
